{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9829546b457e4ca2",
   "metadata": {},
   "source": [
    "# REINFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import random\n",
    "\n",
    "from collections import deque, namedtuple\n",
    "from itertools import count\n",
    "from time import time\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium.vector import AsyncVectorEnv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils as utils\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35a7a0da379a7907",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device_name = \"cpu\"\n",
    "\n",
    "if False:\n",
    "    if torch.cuda.is_available():\n",
    "        device_name = \"cuda\"\n",
    "    elif torch.mps.is_available():\n",
    "        device_name = \"mps\"\n",
    "    # elif torch.hip.is_available():\n",
    "    #     device_name = \"hip\"\n",
    "    elif torch.mtia.is_available():\n",
    "        device_name = \"mtia\"\n",
    "    elif torch.xpu.is_available():\n",
    "        device_name = \"xpu\"\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(f\"device: {device_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0ad38480eece59",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c20eb4be516024a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/toshi_pro/Documents/github-sub/machine-learning\")\n",
    "# sys.path.append(\"/Users/toshi/Documents/school/machine-learning\")\n",
    "# sys.path.append(r\"C:\\Users\\takat\\PycharmProjects\\machine-learning\")\n",
    "import flowdata\n",
    "import flowenv\n",
    "\n",
    "def make_env(phase=\"train\"):\n",
    "    def _init():\n",
    "        if phase == \"train\":\n",
    "            raw_data_train, raw_data_test = flowdata.flow_data.using_data()\n",
    "            return gym.make(\"flowenv/Flow-v1\", data=raw_data_train)\n",
    "        else:\n",
    "            raw_data_train, raw_data_test = flowdata.flow_data.using_data()\n",
    "            return gym.make(\"flowenv/Flow-v1\", data=raw_data_test)\n",
    "    return _init\n",
    "\n",
    "NUM_ENVS = 4\n",
    "\n",
    "raw_data_train, raw_data_test = flowdata.flow_data.using_data()\n",
    "\n",
    "\n",
    "train_envs = AsyncVectorEnv([make_env() for _ in range(NUM_ENVS)])\n",
    "test_envs = AsyncVectorEnv([make_env(\"test\") for _ in range(NUM_ENVS)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480cd4e937dd0e7a",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b2c5d2dc4692746",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "Transaction = namedtuple('Transaction', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        # self.capacity = capacity\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        self.memory.append(Transaction(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "Trajectory = namedtuple('Trajectory', (\"rewards\", \"log_probs\"))\n",
    "\n",
    "class EpisodeMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        # self.capacity = capacity\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        self.memory.append(Trajectory(*args))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "    # last batch_size memory output\n",
    "    def sample(self, batch_size):\n",
    "        return list(self.memory)[-batch_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f366eff4c463bc1",
   "metadata": {},
   "source": [
    "## Plot rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "986abee18b347dab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_accuracy(accuracy_list: list, show_result=False):\n",
    "    plt.figure(1)\n",
    "    # durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "\n",
    "    if show_result:\n",
    "        plt.title(\"Result\")\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title(\"Training...\")\n",
    "    means = [accuracy_list[0]]\n",
    "    for i in range(1, len(accuracy_list)):\n",
    "        means.append(np.mean(accuracy_list[0:i]))\n",
    "\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    # plt.plot(rewards)\n",
    "    plt.plot(means, color=\"red\")\n",
    "    plt.grid()\n",
    "\n",
    "    plt.pause(0.001)\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f8d088cc400a79",
   "metadata": {},
   "source": [
    "### Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f781b493f2dee8a4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_metrics(metrics_dict: dict, show_result=False):\n",
    "    display.clear_output(wait=True)\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "    ac = fig.add_subplot(3, 2, 1)\n",
    "    ac.plot(metrics_dict[\"accuracy\"], label=\"accuracy\")\n",
    "    ac.grid()\n",
    "    ac.set_title(\"Accuracy\")\n",
    "\n",
    "    pr = fig.add_subplot(3, 2, 2)\n",
    "    pr.plot(metrics_dict[\"precision\"], label=\"precision\", color=\"green\")\n",
    "    pr.grid()\n",
    "    pr.set_title(\"Precision\")\n",
    "\n",
    "    re = fig.add_subplot(3, 2, 3)\n",
    "    re.plot(metrics_dict[\"recall\"], label=\"recall\", color=\"red\")\n",
    "    re.grid()\n",
    "    re.set_title(\"Recall\")\n",
    "\n",
    "    f1 = fig.add_subplot(3, 2, 4)\n",
    "    f1.plot(metrics_dict[\"f1\"], label=\"f1\", color=\"black\")\n",
    "    f1.grid()\n",
    "    f1.set_title(\"F1\")\n",
    "\n",
    "    fpr = fig.add_subplot(3, 2, 5)\n",
    "    fpr.plot(metrics_dict[\"fpr\"], label=\"fpr\", color=\"purple\")\n",
    "    fpr.grid()\n",
    "    fpr.set_title(\"FPR\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.pause(0.001)\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())\n",
    "\n",
    "\n",
    "def calculate_metrics(tp, tn, fp, fn):\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    precision = tp / (tp + fp) if tp + fp != 0 else -1\n",
    "    recall = tp / (tp + fn) if tp + fn != 0 else -1\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0.0\n",
    "    fpr = fp / (fp + tn) if fp + tn != 0 else 0.0\n",
    "\n",
    "    if precision < 0:\n",
    "        precision = 0.0\n",
    "    if recall < 0:\n",
    "        recall = 0.0\n",
    "    return accuracy, precision, recall, f1, fpr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09a75ff736ef3f0",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a004798cb2fc841",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.common_fc = nn.Sequential(\n",
    "            nn.Linear(n_inputs, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.probs = nn.Sequential(\n",
    "            nn.Linear(128, n_outputs),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.common_fc(x)\n",
    "        probs = self.probs(x)\n",
    "        return probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821ee49e58d3557a",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1fa23955fd1c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-5\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b52e62d70492c4",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45fb7bba5e7d4c19",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "num_episodes = 10000\n",
    "\n",
    "n_inputs = train_envs.single_observation_space.shape[0]\n",
    "n_outputs = train_envs.single_action_space.n\n",
    "\n",
    "policy_net = PolicyNetwork(n_inputs, n_outputs).to(device)\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LR)\n",
    "\n",
    "steps_done = 0\n",
    "memory = ReplayMemory(1000000)\n",
    "episode_memory = EpisodeMemory(100000)\n",
    "returns = []\n",
    "episode_accuracy = []\n",
    "episode_metrics = {\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1\": [],\n",
    "    \"fpr\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540ad37010e273fd",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f71fba0aad48cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(states):\n",
    "    states = states.clone().detach().requires_grad_(True)\n",
    "    probs = policy_net(states)\n",
    "\n",
    "    distributions = torch.distributions.Categorical(probs)\n",
    "    actions = distributions.sample()\n",
    "    log_probs = distributions.log_prob(actions)\n",
    "\n",
    "    return actions, log_probs\n",
    "\n",
    "def calculate_returns(rewards):\n",
    "    returns = torch.zeros_like(rewards)\n",
    "    G = 0\n",
    "    try:\n",
    "        for i in reversed(range(len(rewards))):\n",
    "            G = rewards[i] + GAMMA * G\n",
    "            returns[i] = G\n",
    "    except:\n",
    "        returns[0] = rewards[0]\n",
    "    return returns.clone().detach().requires_grad_(True)\n",
    "\n",
    "def optimize_model():\n",
    "    # print(log_probs)\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    trajectory = episode_memory.sample(BATCH_SIZE)\n",
    "    batch = Trajectory(*zip(*trajectory))\n",
    "\n",
    "    rewards = torch.cat(batch.rewards).squeeze()\n",
    "    log_probs = torch.cat(batch.log_probs).squeeze()\n",
    "\n",
    "    returns = calculate_returns(rewards)\n",
    "    baseline = returns.mean()\n",
    "    advantage = returns - baseline\n",
    "\n",
    "    loss = -(log_probs * advantage).mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0b2384c576de98",
   "metadata": {},
   "source": [
    "REINFORCE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcffe90ed4225c6",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1f4d16a6f258368",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    MODEL_PATH = \"no4_reinforce.pth\"\n",
    "\n",
    "    # load the model\n",
    "    trained_network = PolicyNetwork(n_inputs, n_outputs).to(device)\n",
    "    trained_network.load_state_dict(torch.load(MODEL_PATH, map_location=device, weights_only=True))\n",
    "    trained_network.eval()\n",
    "\n",
    "    # test the model\n",
    "\n",
    "    confusion_array = np.zeros((2, 2), dtype=np.int32)\n",
    "    metrics_dictionary = {\n",
    "        \"accuracy\": [],\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1\": [],\n",
    "        \"fpr\": []\n",
    "    }\n",
    "\n",
    "    for i_loop in range(100):\n",
    "        test_raw_state, _ = test_env.reset()\n",
    "        test_state = torch.tensor(test_raw_state, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        for t in count():\n",
    "            with torch.no_grad():\n",
    "                prob_distribution, _ = trained_network(test_state)\n",
    "                test_action = torch.multinomial(prob_distribution, 1)\n",
    "\n",
    "            test_raw_next_state, test_reward, test_terminated, test_truncated, test_info = test_env.step(test_action.item())\n",
    "\n",
    "            # calculate confusion matrix\n",
    "            raw = 0 if test_reward == 1 else 1\n",
    "\n",
    "            # test_info = (row, column) means confusion matrix index\n",
    "            index = test_info[\"confusion_position\"]\n",
    "            confusion_array[index[0], index[1]] += 1\n",
    "\n",
    "            if test_terminated:\n",
    "                break\n",
    "\n",
    "            # make next state tensor and update state\n",
    "            test_state = torch.tensor(test_raw_next_state, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        # calculate metrics\n",
    "        tp = confusion_array[0, 0]\n",
    "        tn = confusion_array[1, 1]\n",
    "        fp = confusion_array[0, 1]\n",
    "        fn = confusion_array[1, 0]\n",
    "\n",
    "        accuracy, precision, recall, f1, fpr = calculate_metrics(tp, tn, fp, fn)\n",
    "        metrics_dictionary[\"accuracy\"].append(accuracy)\n",
    "        metrics_dictionary[\"precision\"].append(precision)\n",
    "        metrics_dictionary[\"recall\"].append(recall)\n",
    "        metrics_dictionary[\"f1\"].append(f1)\n",
    "        metrics_dictionary[\"fpr\"].append(fpr)\n",
    "        # print(tp, tn, fp, tn)\n",
    "\n",
    "    return [np.mean(metrics_dictionary[\"accuracy\"]), np.mean(metrics_dictionary[\"precision\"]), np.mean(metrics_dictionary[\"recall\"]), np.mean(metrics_dictionary[\"f1\"]), np.mean(metrics_dictionary[\"fpr\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bad6848-1ef4-497a-9f97-3e65c1fab15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6b4f904-7295-47a2-a9b5-5916bc10f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_states, info = train_envs.reset()\n",
    "states = torch.tensor(initial_states, device=device, dtype=torch.float32).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01f00488-2689-49a1-8cfd-e81eb8932a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1]]) tensor([[-1.1921e-07, -1.1921e-07, -1.1921e-07, -1.1921e-07]],\n",
      "       grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "actions, log_probs = select_action(states)\n",
    "print(actions, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6c6c026-5530-42e6-aa01-8a5ec934de83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1]]\n",
      "[1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(actions.cpu().numpy())\n",
    "actions_np = actions.cpu().numpy()[0]\n",
    "print(actions_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b81a6015-ce37-4a1c-9a93-1226f7ad441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_envs.step_async(actions_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ff32530-277e-4c79-98e6-da2bd8e7adfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_states, rewards, terminated, truncated, info = train_envs.step_wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f88b023-54d5-47c6-bb7c-52474cf9c928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0) (0, 0) (0, 0) (0, 0)]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfusion_position\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfusion_position\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mconfusion_matrix\u001b[49m[item[\u001b[38;5;241m0\u001b[39m], item[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "print(info[\"confusion_position\"])\n",
    "for item in info[\"confusion_position\"]:\n",
    "    confusion_matrix[item[0], item[1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42929f85-6881-43b6-be6e-99e7860b5576",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, done in enumerate(terminated):\n",
    "    if done:\n",
    "        next_states[i], _ = train_envs.reset_at(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5755164-41e3-49c8-911f-b3e1fc5a450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = torch.tensor(rewards, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2225ab0d482517",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    random.seed(i_episode)\n",
    "    confusion_matrix = np.zeros((2,2), dtype=int)\n",
    "    sum_reward = 0\n",
    "    # print(i_episode)\n",
    "\n",
    "    initial_states, info = train_envs.reset()\n",
    "    states = torch.tensor(initial_states, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "    # states = initial_states.clone().detach().requires_grad_(True)\n",
    "\n",
    "    one_rewards = []\n",
    "    one_log_probs = []\n",
    "\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        actions, log_probs = select_action(states)\n",
    "\n",
    "        next_states, rewards, terminated, truncated, info = train_envs.step(actions)\n",
    "\n",
    "        # calculate confusion matrix\n",
    "        for item in info[\"confusion_position\"]:\n",
    "            confusion_matrix[item[0], item[1]] += 1\n",
    "\n",
    "        rewards = torch.tensor(rewards, device=device, dtype=torch.float32)\n",
    "\n",
    "        # store the transition in memory\n",
    "        one_rewards.append(rewards)\n",
    "        one_log_probs.append(log_probs)\n",
    "        \n",
    "        # to tensor\n",
    "        next_states = torch.tensor(next_states, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        if True in terminated:\n",
    "            break\n",
    "    \n",
    "        states = next_states\n",
    "        print(t)\n",
    "    \n",
    "    accuracy = (confusion_matrix[0, 0] + confusion_matrix[1, 1]) / confusion_matrix.sum()\n",
    "    episode_accuracy.append(accuracy)\n",
    "    \n",
    "    one_rewards = torch.cat(one_rewards)\n",
    "    one_log_probs = torch.cat(one_log_probs)\n",
    "    episode_memory.push(one_rewards, one_log_probs)\n",
    "\n",
    "    # not reuse graph\n",
    "    if i_episode > 0 and i_episode % 8 == 0:\n",
    "        print(f\"\\r{i_episode:5}\", end=\"\")\n",
    "        optimize_model()\n",
    "    \n",
    "    if i_episode > 0 and i_episode % 25 == 0:\n",
    "        plot_accuracy(episode_accuracy)\n",
    "\n",
    "else:\n",
    "    torch.save(policy_net.state_dict(), \"no3_reinforce.pth\")  # save the model\n",
    "\"\"\"\n",
    "    if i_episode > 0 and i_episode % 100 == 0:\n",
    "        torch.save(policy_net.state_dict(), \"no3_reinforce.pth\")  # save the model\n",
    "\n",
    "        print(f\"Episode {i_episode}: {sum_reward}\")\n",
    "        ac, pr, re, f1, fp = test()\n",
    "        episode_metrics[\"accuracy\"].append(ac)\n",
    "        episode_metrics[\"precision\"].append(pr)\n",
    "        episode_metrics[\"recall\"].append(re)\n",
    "        episode_metrics[\"f1\"].append(f1)\n",
    "        episode_metrics[\"fpr\"].append(fp)\n",
    "        plot_metrics(episode_metrics)\n",
    "\"\"\"\n",
    "\n",
    "# complete the episode\n",
    "plot_metrics(episode_metrics, show_result=True)\n",
    "plot_accuracy(episode_accuracy, show_result=True)\n",
    "\n",
    "train_envs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6864d-8fb3-47be-952d-8a2cac4a79c0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Episode {i_episode}: {sum_reward}\")\n",
    "ac, pr, re, f1, fp = test()\n",
    "episode_metrics[\"accuracy\"].append(ac)\n",
    "episode_metrics[\"precision\"].append(pr)\n",
    "episode_metrics[\"recall\"].append(re)\n",
    "episode_metrics[\"f1\"].append(f1)\n",
    "episode_metrics[\"fpr\"].append(fp)\n",
    "plot_metrics(episode_metrics, show_result=True)\n",
    "print(ac, pr, re, f1, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9740beca7384b44",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bcf181-2fcc-4004-9f2c-5f41762b7f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
