{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9829546b457e4ca2",
   "metadata": {},
   "source": [
    "# REINFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import random\n",
    "\n",
    "from collections import deque, namedtuple\n",
    "from itertools import count\n",
    "from time import time\n",
    "\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils as utils\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35a7a0da379a7907",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n"
     ]
    }
   ],
   "source": [
    "device_name = \"cpu\"\n",
    "\n",
    "if True:\n",
    "    if torch.cuda.is_available():\n",
    "        device_name = \"cuda\"\n",
    "    elif torch.mps.is_available():\n",
    "        device_name = \"mps\"\n",
    "    # elif torch.hip.is_available():\n",
    "    #     device_name = \"hip\"\n",
    "    elif torch.mtia.is_available():\n",
    "        device_name = \"mtia\"\n",
    "    elif torch.xpu.is_available():\n",
    "        device_name = \"xpu\"\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(f\"device: {device_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0ad38480eece59",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c20eb4be516024a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/toshi_pro/Documents/github-sub/machine-learning\")\n",
    "# sys.path.append(\"/Users/toshi/Documents/school/machine-learning\")\n",
    "# sys.path.append(r\"C:\\Users\\takat\\PycharmProjects\\machine-learning\")\n",
    "import flowdata\n",
    "import flowenv\n",
    "\n",
    "raw_data_train, raw_data_test = flowdata.flow_data.using_data()\n",
    "raw_data_train.dropna(how=\"any\")\n",
    "raw_data_test.dropna(how=\"any\")\n",
    "# print(raw_data_train)\n",
    "# train_env = gym.make(\"flowenv/FlowTrain-v0\", data=raw_data_train)\n",
    "train_env = gym.make(\"flowenv/Flow-v1\", data=raw_data_train)\n",
    "# test_env = gym.make(\"flowenv/FlowTest-v0\", data=raw_data_test)\n",
    "test_env = gym.make(\"flowenv/Flow-v1\", data=raw_data_test)\n",
    "\n",
    "# pd.set_option('display.max_columns', 1000)\n",
    "# print(raw_data_train[raw_data_train[\"Dst Port\"] == 39964])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480cd4e937dd0e7a",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b2c5d2dc4692746",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transaction = namedtuple('Transaction', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        # self.capacity = capacity\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        self.memory.append(Transaction(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "Trajectory = namedtuple('Trajectory', (\"rewards\", \"log_probs\"))\n",
    "\n",
    "class EpisodeMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        # self.capacity = capacity\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        self.memory.append(Trajectory(*args))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "    # last batch_size memory output\n",
    "    def sample(self, batch_size):\n",
    "        return list(self.memory)[-batch_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f366eff4c463bc1",
   "metadata": {},
   "source": [
    "## Plot rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "986abee18b347dab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_rewards(rewards: list, show_result=False):\n",
    "    plt.figure(1)\n",
    "    # durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "\n",
    "    if show_result:\n",
    "        plt.title(\"Result\")\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title(\"Training...\")\n",
    "    means = [rewards[0]]\n",
    "    for i in range(1, len(rewards)):\n",
    "        means.append(np.mean(rewards[0:i]))\n",
    "\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    # plt.plot(rewards)\n",
    "    plt.plot(means, color=\"red\")\n",
    "    plt.grid()\n",
    "\n",
    "    plt.pause(0.001)\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f8d088cc400a79",
   "metadata": {},
   "source": [
    "### Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f781b493f2dee8a4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_metrics(metrics_dict: dict, show_result=False):\n",
    "    display.clear_output(wait=True)\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "    ac = fig.add_subplot(3, 2, 1)\n",
    "    ac.plot(metrics_dict[\"accuracy\"], label=\"accuracy\")\n",
    "    ac.grid()\n",
    "    ac.set_title(\"Accuracy\")\n",
    "\n",
    "    pr = fig.add_subplot(3, 2, 2)\n",
    "    pr.plot(metrics_dict[\"precision\"], label=\"precision\", color=\"green\")\n",
    "    pr.grid()\n",
    "    pr.set_title(\"Precision\")\n",
    "\n",
    "    re = fig.add_subplot(3, 2, 3)\n",
    "    re.plot(metrics_dict[\"recall\"], label=\"recall\", color=\"red\")\n",
    "    re.grid()\n",
    "    re.set_title(\"Recall\")\n",
    "\n",
    "    f1 = fig.add_subplot(3, 2, 4)\n",
    "    f1.plot(metrics_dict[\"f1\"], label=\"f1\", color=\"black\")\n",
    "    f1.grid()\n",
    "    f1.set_title(\"F1\")\n",
    "\n",
    "    fpr = fig.add_subplot(3, 2, 5)\n",
    "    fpr.plot(metrics_dict[\"fpr\"], label=\"fpr\", color=\"purple\")\n",
    "    fpr.grid()\n",
    "    fpr.set_title(\"FPR\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.pause(0.001)\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())\n",
    "\n",
    "\n",
    "def calculate_metrics(tp, tn, fp, fn):\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    precision = tp / (tp + fp) if tp + fp != 0 else -1\n",
    "    recall = tp / (tp + fn) if tp + fn != 0 else -1\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0.0\n",
    "    fpr = fp / (fp + tn) if fp + tn != 0 else 0.0\n",
    "\n",
    "    if precision < 0:\n",
    "        precision = 0.0\n",
    "    if recall < 0:\n",
    "        recall = 0.0\n",
    "    return accuracy, precision, recall, f1, fpr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09a75ff736ef3f0",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a004798cb2fc841",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.common_fc = nn.Sequential(\n",
    "            nn.Linear(n_inputs, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.probs = nn.Sequential(\n",
    "            nn.Linear(128, n_outputs),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        self.fc_value = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.common_fc(x)\n",
    "        probs = self.probs(x)\n",
    "        value = self.fc_value(x)\n",
    "        return probs, value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821ee49e58d3557a",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1fa23955fd1c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b52e62d70492c4",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45fb7bba5e7d4c19",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "num_episodes = 10000\n",
    "\n",
    "n_inputs = train_env.observation_space.shape[0]\n",
    "n_outputs = train_env.action_space.n\n",
    "\n",
    "policy_net = PolicyNetwork(n_inputs, n_outputs).to(device)\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LR)\n",
    "\n",
    "steps_done = 0\n",
    "memory = ReplayMemory(1000000)\n",
    "episode_memory = EpisodeMemory(100000)\n",
    "episode_rewards = []\n",
    "returns = []\n",
    "episode_accuracy = []\n",
    "episode_metrics = {\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1\": [],\n",
    "    \"fpr\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540ad37010e273fd",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f71fba0aad48cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state: torch.Tensor):\n",
    "    prob_distri, _ = policy_net(state) # return probability of actions\n",
    "    try:\n",
    "        action = torch.multinomial(prob_distri, 1)\n",
    "    except:\n",
    "        raise Exception(state, prob_distri)\n",
    "    print(prob_distri)\n",
    "    return prob_distri, action # return index of action\n",
    "\n",
    "def calculate_returns(rewards):\n",
    "    returns = torch.zeros_like(rewards)\n",
    "    G = 0\n",
    "    try:\n",
    "        for i in reversed(range(len(rewards))):\n",
    "            G = rewards[i] + GAMMA * G\n",
    "            returns[i] = G\n",
    "    except:\n",
    "        returns[0] = rewards[0]\n",
    "    return returns.clone().detach().requires_grad_(True)\n",
    "\n",
    "def optimize_model():\n",
    "    # print(log_probs)\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    trajectory = episode_memory.sample(BATCH_SIZE)\n",
    "    batch = Trajectory(*zip(*trajectory))\n",
    "\n",
    "    rewards = torch.cat(batch.rewards).squeeze()\n",
    "    log_probs = torch.cat(batch.log_probs).squeeze()\n",
    "\n",
    "    returns = calculate_returns(rewards)\n",
    "    baseline = returns.mean()\n",
    "    advantage = returns - baseline\n",
    "\n",
    "    loss = -(log_probs * advantage).mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0b2384c576de98",
   "metadata": {},
   "source": [
    "REINFORCE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcffe90ed4225c6",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1f4d16a6f258368",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    MODEL_PATH = \"no3_reinforce.pth\"\n",
    "\n",
    "    # load the model\n",
    "    trained_network = PolicyNetwork(n_inputs, n_outputs).to(device)\n",
    "    trained_network.load_state_dict(torch.load(MODEL_PATH, map_location=device, weights_only=True))\n",
    "    trained_network.eval()\n",
    "\n",
    "    # test the model\n",
    "\n",
    "    confusion_array = np.zeros((2, 2), dtype=np.int32)\n",
    "    metrics_dictionary = {\n",
    "        \"accuracy\": [],\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1\": [],\n",
    "        \"fpr\": []\n",
    "    }\n",
    "\n",
    "    for _ in range(100):\n",
    "        test_raw_state, _ = test_env.reset()\n",
    "        test_state = torch.tensor(test_raw_state, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        for t in count():\n",
    "            with torch.no_grad():\n",
    "                prob_distribution, _ = trained_network(test_state)\n",
    "                test_action = torch.multinomial(prob_distribution, 1)\n",
    "\n",
    "            test_raw_next_state, test_reward, test_terminated, test_truncated, test_info = test_env.step(test_action.item())\n",
    "\n",
    "            # calculate confusion matrix\n",
    "            raw = 0 if test_reward == 1 else 1\n",
    "\n",
    "            # test_info = (row, column) means confusion matrix index\n",
    "            index = test_info[\"confusion_position\"]\n",
    "            confusion_array[index[0], index[1]] += 1\n",
    "\n",
    "            if test_terminated:\n",
    "                break\n",
    "\n",
    "            # make next state tensor and update state\n",
    "            test_state = torch.tensor(test_raw_next_state, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        # calculate metrics\n",
    "        tp = confusion_array[1, 1]\n",
    "        tn = confusion_array[0, 0]\n",
    "        fp = confusion_array[1, 0]\n",
    "        fn = confusion_array[0, 1]\n",
    "\n",
    "        accuracy, precision, recall, f1, fpr = calculate_metrics(tp, tn, fp, fn)\n",
    "        metrics_dictionary[\"accuracy\"].append(accuracy)\n",
    "        metrics_dictionary[\"precision\"].append(precision)\n",
    "        metrics_dictionary[\"recall\"].append(recall)\n",
    "        metrics_dictionary[\"f1\"].append(f1)\n",
    "        metrics_dictionary[\"fpr\"].append(fpr)\n",
    "        # print(tp, tn, fp, tn)\n",
    "\n",
    "    return [np.mean(metrics_dictionary[\"accuracy\"]), np.mean(metrics_dictionary[\"precision\"]), np.mean(metrics_dictionary[\"recall\"]), np.mean(metrics_dictionary[\"f1\"]), np.mean(metrics_dictionary[\"fpr\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bad6848-1ef4-497a-9f97-3e65c1fab15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f2225ab0d482517",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5275, 0.4725]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5262, 0.4738]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5255, 0.4745]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5234, 0.4766]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5275, 0.4725]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5275, 0.4725]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5259, 0.4741]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5248, 0.4752]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5254, 0.4746]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5271, 0.4729]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5280, 0.4720]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5253, 0.4747]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5275, 0.4725]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5259, 0.4741]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5245, 0.4755]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5255, 0.4745]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5253, 0.4747]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5256, 0.4744]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5266, 0.4734]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5277, 0.4723]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5275, 0.4725]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5254, 0.4746]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5272, 0.4728]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5278, 0.4722]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5275, 0.4725]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5271, 0.4729]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5254, 0.4746]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5221, 0.4779]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5277, 0.4723]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5248, 0.4752]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5255, 0.4745]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5221, 0.4779]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5277, 0.4723]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5279, 0.4721]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5253, 0.4747]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5277, 0.4723]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5254, 0.4746]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5259, 0.4741]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5254, 0.4746]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5288, 0.4712]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5248, 0.4752]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5266, 0.4734]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5254, 0.4746]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5249, 0.4751]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5272, 0.4728]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5254, 0.4746]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5275, 0.4725]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5275, 0.4725]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5275, 0.4725]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5255, 0.4745]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5246, 0.4754]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5254, 0.4746]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5272, 0.4728]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5254, 0.4746]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5253, 0.4747]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5264, 0.4736]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5259, 0.4741]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5275, 0.4725]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5263, 0.4737]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5254, 0.4746]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5221, 0.4779]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5265, 0.4735]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5275, 0.4725]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5269, 0.4731]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5254, 0.4746]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5275, 0.4725]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5253, 0.4747]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5259, 0.4741]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5259, 0.4741]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5271, 0.4729]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5252, 0.4748]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5215, 0.4785]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5254, 0.4746]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5245, 0.4755]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5271, 0.4729]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5290, 0.4710]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5272, 0.4728]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5279, 0.4721]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5266, 0.4734]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5264, 0.4736]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5267, 0.4733]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5256, 0.4744]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5272, 0.4728]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5252, 0.4748]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5242, 0.4758]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5265, 0.4735]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5256, 0.4744]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5254, 0.4746]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5241, 0.4759]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5269, 0.4731]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5254, 0.4746]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5278, 0.4722]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5255, 0.4745]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5235, 0.4765]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5280, 0.4720]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5255, 0.4745]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5259, 0.4741]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5262, 0.4738]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5255, 0.4745]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5253, 0.4747]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5254, 0.4746]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5272, 0.4728]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5271, 0.4729]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5275, 0.4725]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5275, 0.4725]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5269, 0.4731]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5275, 0.4725]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5254, 0.4746]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5255, 0.4745]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5251, 0.4749]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5253, 0.4747]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5254, 0.4746]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5248, 0.4752]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5259, 0.4741]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5253, 0.4747]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5257, 0.4743]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5254, 0.4746]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5255, 0.4745]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5259, 0.4741]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5255, 0.4745]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5275, 0.4725]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5259, 0.4741]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5243, 0.4757]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5263, 0.4737]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5257, 0.4743]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5254, 0.4746]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5275, 0.4725]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5271, 0.4729]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5259, 0.4741]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5277, 0.4723]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5264, 0.4736]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5253, 0.4747]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5254, 0.4746]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5253, 0.4747]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5266, 0.4734]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5254, 0.4746]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5274, 0.4726]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5270, 0.4730]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5243, 0.4757]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5272, 0.4728]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5275, 0.4725]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5257, 0.4743]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5246, 0.4754]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5275, 0.4725]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5260, 0.4740]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5276, 0.4724]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5255, 0.4745]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5255, 0.4745]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5268, 0.4732]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5261, 0.4739]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4727]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 60\u001b[0m\n\u001b[1;32m     56\u001b[0m     base \u001b[38;5;241m=\u001b[39m confusion_matrix[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m confusion_matrix[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     57\u001b[0m     episode_accuracy\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     58\u001b[0m         confusion_matrix[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m base \u001b[38;5;28;01mif\u001b[39;00m base \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     59\u001b[0m     )\n\u001b[0;32m---> 60\u001b[0m     \u001b[43mplot_rewards\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisode_accuracy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m##\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(policy_net\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno3_reinforce.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# save the model\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m, in \u001b[0;36mplot_rewards\u001b[0;34m(rewards, show_result)\u001b[0m\n\u001b[1;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(means, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mgrid()\n\u001b[0;32m---> 20\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpause\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_ipython:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m show_result:\n",
      "File \u001b[0;32m~/Documents/github-sub/machine-learning/.venv/lib/python3.12/site-packages/matplotlib/pyplot.py:756\u001b[0m, in \u001b[0;36mpause\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    754\u001b[0m canvas \u001b[38;5;241m=\u001b[39m manager\u001b[38;5;241m.\u001b[39mcanvas\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m canvas\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mstale:\n\u001b[0;32m--> 756\u001b[0m     \u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m show(block\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    758\u001b[0m canvas\u001b[38;5;241m.\u001b[39mstart_event_loop(interval)\n",
      "File \u001b[0;32m~/Documents/github-sub/machine-learning/.venv/lib/python3.12/site-packages/matplotlib/backend_bases.py:1891\u001b[0m, in \u001b[0;36mFigureCanvasBase.draw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_idle_drawing:\n\u001b[1;32m   1890\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_idle_draw_cntx():\n\u001b[0;32m-> 1891\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github-sub/machine-learning/.venv/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py:382\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\u001b[38;5;241m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\n\u001b[1;32m    381\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdraw()\n",
      "File \u001b[0;32m~/Documents/github-sub/machine-learning/.venv/lib/python3.12/site-packages/matplotlib/artist.py:94\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 94\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[1;32m     96\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/Documents/github-sub/machine-learning/.venv/lib/python3.12/site-packages/matplotlib/artist.py:71\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/github-sub/machine-learning/.venv/lib/python3.12/site-packages/matplotlib/figure.py:3257\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3254\u001b[0m             \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   3256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 3257\u001b[0m     \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3260\u001b[0m     renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   3261\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/github-sub/machine-learning/.venv/lib/python3.12/site-packages/matplotlib/image.py:134\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[0;32m--> 134\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/github-sub/machine-learning/.venv/lib/python3.12/site-packages/matplotlib/artist.py:71\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/github-sub/machine-learning/.venv/lib/python3.12/site-packages/matplotlib/axes/_base.py:3145\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3142\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m spine \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspines\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m   3143\u001b[0m         artists\u001b[38;5;241m.\u001b[39mremove(spine)\n\u001b[0;32m-> 3145\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_title_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxison:\n\u001b[1;32m   3148\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _axis \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axis_map\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/Documents/github-sub/machine-learning/.venv/lib/python3.12/site-packages/matplotlib/axes/_base.py:3099\u001b[0m, in \u001b[0;36m_AxesBase._update_title_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3097\u001b[0m     _log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop of Axes not in the figure, so title not moved\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   3098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 3099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtitle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_window_extent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mymin \u001b[38;5;241m<\u001b[39m top:\n\u001b[1;32m   3100\u001b[0m     _, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransAxes\u001b[38;5;241m.\u001b[39minverted()\u001b[38;5;241m.\u001b[39mtransform((\u001b[38;5;241m0\u001b[39m, top))\n\u001b[1;32m   3101\u001b[0m     title\u001b[38;5;241m.\u001b[39mset_position((x, y))\n",
      "File \u001b[0;32m~/Documents/github-sub/machine-learning/.venv/lib/python3.12/site-packages/matplotlib/text.py:969\u001b[0m, in \u001b[0;36mText.get_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get window extent of text w/o renderer. You likely \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    966\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwant to call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure.draw_without_rendering()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(fig, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m--> 969\u001b[0m     bbox, info, descent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_renderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_unitless_position()\n\u001b[1;32m    971\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_transform()\u001b[38;5;241m.\u001b[39mtransform((x, y))\n",
      "File \u001b[0;32m~/Documents/github-sub/machine-learning/.venv/lib/python3.12/site-packages/matplotlib/text.py:373\u001b[0m, in \u001b[0;36mText._get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    370\u001b[0m ys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# Full vertical extent of font, including ascenders and descenders:\u001b[39;00m\n\u001b[0;32m--> 373\u001b[0m _, lp_h, lp_d \u001b[38;5;241m=\u001b[39m \u001b[43m_get_text_metrics_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fontproperties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mismath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTeX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_usetex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m min_dy \u001b[38;5;241m=\u001b[39m (lp_h \u001b[38;5;241m-\u001b[39m lp_d) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_linespacing\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(lines):\n",
      "File \u001b[0;32m~/Documents/github-sub/machine-learning/.venv/lib/python3.12/site-packages/matplotlib/text.py:69\u001b[0m, in \u001b[0;36m_get_text_metrics_with_cache\u001b[0;34m(renderer, text, fontprop, ismath, dpi)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call ``renderer.get_text_width_height_descent``, caching the results.\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Cached based on a copy of fontprop so that later in-place mutations of\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# the passed-in argument do not mess up the cache.\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_text_metrics_with_cache_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontprop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mismath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github-sub/machine-learning/.venv/lib/python3.12/site-packages/matplotlib/text.py:77\u001b[0m, in \u001b[0;36m_get_text_metrics_with_cache_impl\u001b[0;34m(renderer_ref, text, fontprop, ismath, dpi)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(\u001b[38;5;241m4096\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_text_metrics_with_cache_impl\u001b[39m(\n\u001b[1;32m     75\u001b[0m         renderer_ref, text, fontprop, ismath, dpi):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# dpi is unused, but participates in cache invalidation (via the renderer).\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrenderer_ref\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text_width_height_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontprop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mismath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github-sub/machine-learning/.venv/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py:221\u001b[0m, in \u001b[0;36mRendererAgg.get_text_width_height_descent\u001b[0;34m(self, s, prop, ismath)\u001b[0m\n\u001b[1;32m    219\u001b[0m font\u001b[38;5;241m.\u001b[39mset_text(s, \u001b[38;5;241m0.0\u001b[39m, flags\u001b[38;5;241m=\u001b[39mget_hinting_flag())\n\u001b[1;32m    220\u001b[0m w, h \u001b[38;5;241m=\u001b[39m font\u001b[38;5;241m.\u001b[39mget_width_height()  \u001b[38;5;66;03m# width and height of unrotated string\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[43mfont\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m w \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64.0\u001b[39m  \u001b[38;5;66;03m# convert from subpixels\u001b[39;00m\n\u001b[1;32m    223\u001b[0m h \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64.0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWnRJREFUeJzt3XlcVFX/B/DPDMsACkqg4IK7oqSiohKZW6KmlZo+Zf00jUrTpCzSynLJpTAz08qkTLOy1HrKpTKT3B5JRRMtNSU3xFRAUgFBWWbu74/jHRjZZoYZ5l7m8369eDHM3Llz5gjy4XzPOVcjSZIEIiIiIieidXQDiIiIiKobAxARERE5HQYgIiIicjoMQEREROR0GICIiIjI6TAAERERkdNhACIiIiKnwwBERERETocBiIiIiJwOAxARqdITTzyBZs2aWfXcN954AxqNxrYNIiJVYQAiIpvSaDRmfezcudPRTSUiJ6bhtcCIyJZWr15t8vUXX3yB+Ph4fPnllyb39+/fHwEBAVa/TmFhIQwGA3Q6ncXPLSoqQlFRETw8PKx+fSJSNwYgIrKr6OhoLF26FJX9V5OXlwcvL69qahUROTuWwIio2vXp0wft27fHwYMH0atXL3h5eeG1114DAGzcuBH3338/GjZsCJ1Oh5YtW2Lu3LnQ6/Um57h9DlBKSgo0Gg0WLlyITz75BC1btoROp0O3bt1w4MABk+eWNQdIo9EgOjoaGzZsQPv27aHT6XDnnXdiy5Ytpdq/c+dOdO3aFR4eHmjZsiU+/vhjzisiUhlXRzeAiJzTv//+i0GDBuHRRx/F6NGjjeWwVatWoXbt2oiJiUHt2rWxfft2zJw5E9nZ2XjnnXcqPe/XX3+NnJwcPPPMM9BoNFiwYAGGDx+OM2fOwM3NrcLnJiQk4Pvvv8ezzz4Lb29vvP/++xgxYgRSU1Ph5+cHADh06BDuu+8+NGjQALNnz4Zer8ecOXNQr169qncKEVUbBiAicoi0tDTExcXhmWeeMbn/66+/hqenp/HrCRMmYMKECfjoo48wb968Suf8pKam4uTJk/D19QUABAcHY+jQofjll1/wwAMPVPjc48eP46+//kLLli0BAH379kVoaCjWrFmD6OhoAMCsWbPg4uKC3377DQ0bNgQAPPLII2jXrp1lHUBEDsUSGBE5hE6nQ1RUVKn7S4afnJwcZGZmomfPnsjLy8OJEycqPe/IkSON4QcAevbsCQA4c+ZMpc+NjIw0hh8A6NixI3x8fIzP1ev1+PXXXzFs2DBj+AGAVq1aYdCgQZWen4iUgyNAROQQjRo1gru7e6n7jx07hunTp2P79u3Izs42eSwrK6vS8zZp0sTkazkMXb161eLnys+Xn5uRkYEbN26gVatWpY4r6z4iUi4GICJyiJIjPbJr166hd+/e8PHxwZw5c9CyZUt4eHggKSkJr7zyCgwGQ6XndXFxKfN+cxa8VuW5RKQuDEBEpBg7d+7Ev//+i++//x69evUy3n/27FkHtqpY/fr14eHhgVOnTpV6rKz7iEi5OAeIiBRDHoEpOeJSUFCAjz76yFFNMuHi4oLIyEhs2LABFy9eNN5/6tQp/Pzzz6WOT01NLTVvKTMzEydOnEBeXp7xPnl+U2Zmpv0aT0QmGICISDHuvvtu+Pr6YuzYsVi0aBHee+893HXXXYoqQb3xxhsoKipCjx49sGDBAsTGxqJ3795o3759qWPHjBlTanXYhx9+iHbt2mH//v3G+/bv34927drhww8/tHv7iUhgACIixfDz88OPP/6IBg0aYPr06Vi4cCH69++PBQsWOLppRmFhYfj555/h6+uLGTNmYMWKFZgzZw769evHS2sQqQgvhUFEZAPDhg3DsWPHcPLkSUc3hYjMwBEgIiIL3bhxw+TrkydPYvPmzejTp49jGkREFuMIEBGRhRo0aIAnnngCLVq0wLlz57Bs2TLk5+fj0KFDaN26taObR0Rm4DJ4IiIL3XfffVizZg3S0tKg0+kQERGBt956i+GHSEU4AkREREROh3OAiIiIyOkwABEREZHT4RygMhgMBly8eBHe3t7QaDSObg4RERGZQZIk5OTkoGHDhtBqKx7jYQAqw8WLFxEUFOToZhAREZEVzp8/j8aNG1d4DANQGby9vQGIDvTx8bHpuQsLC7F161YMGDAAbm5uNj23M2E/2gb70TbYj7bBfqw6Z+/D7OxsBAUFGX+PV4QBqAxy2cvHx8cuAcjLyws+Pj5O+c1pK+xH22A/2gb70TbYj1XHPhTMmb7CSdBERETkdBiAiIiIyOkwABEREZHTYQAiIiIip8MARERERE6HAYiIiIicDgMQEREROR0GICIiInI6DEBERETkdBiAiIiIyOkoIgAtXboUzZo1g4eHB8LDw7F///5yj121ahU0Go3Jh4eHh/HxwsJCvPLKK+jQoQNq1aqFhg0bYsyYMbh48WJ1vBUiIiJSAYcHoHXr1iEmJgazZs1CUlISQkNDMXDgQGRkZJT7HB8fH1y6dMn4ce7cOeNjeXl5SEpKwowZM5CUlITvv/8eycnJGDJkSHW8HSIiIlIBh18MddGiRRg3bhyioqIAAHFxcfjpp5+wcuVKvPrqq2U+R6PRIDAwsMzH6tSpg/j4eJP7PvzwQ3Tv3h2pqalo0qSJbd8AOUZurqNbQEREKubQEaCCggIcPHgQkZGRxvu0Wi0iIyOxd+/ecp93/fp1NG3aFEFBQRg6dCiOHTtW4etkZWVBo9Ggbt26tmo6OdLGjXD180PzzZsd3RIiIlIph44AZWZmQq/XIyAgwOT+gIAAnDhxosznBAcHY+XKlejYsSOysrKwcOFC3H333Th27BgaN25c6vibN2/ilVdewWOPPQYfH58yz5mfn4/8/Hzj19nZ2QDEfKLCwkJr316Z5PPZ+rzORPvLL3AxGBBw4AD7sYr4/Wgb7EfbYD9WnbP3oSXv2+ElMEtFREQgIiLC+PXdd9+Ndu3a4eOPP8bcuXNNji0sLMQjjzwCSZKwbNmycs8ZGxuL2bNnl7p/69at8PLysl3jS7i9TEfmuysxEQEA6qSk4Bf2o03w+9E22I+2wX6sOmftw7y8PLOPdWgA8vf3h4uLC9LT003uT09PL3eOz+3c3NzQuXNnnDp1yuR+OfycO3cO27dvL3f0BwCmTZuGmJgY49fZ2dkICgrCgAEDKnyeNQoLCxEfH4/+/fvDzc3Npud2Fq5TpgAAPK5eRf/QULg1auTgFqkXvx9tg/1oG+zHqnP2PpQrOOZwaAByd3dHWFgYtm3bhmHDhgEADAYDtm3bhujoaLPOodfrceTIEQwePNh4nxx+Tp48iR07dsDPz6/Cc+h0Ouh0ulL3u7m52e0byJ7nrtGKioCUFOOX7idOwLVZM4c1p6bg96NtsB9tg/1Ydc7ah5a8Z4cvg4+JicHy5cvx+eef4/jx45g4cSJyc3ONq8LGjBmDadOmGY+fM2cOtm7dijNnziApKQmjR4/GuXPn8PTTTwMQ4ec///kPfv/9d3z11VfQ6/VIS0tDWloaCgoKHPIeyYbOnxch6BbNkSMObAwREamVw+cAjRw5EpcvX8bMmTORlpaGTp06YcuWLcaJ0ampqdBqi3Pa1atXMW7cOKSlpcHX1xdhYWHYs2cPQkJCAAAXLlzApk2bAACdOnUyea0dO3agT58+1fK+yE5Onzb5kgGIiIis4fAABADR0dHllrx27txp8vV7772H9957r9xzNWvWDJIk2bJ5pCS3ApCk00GTnw/Nn386uEFERKRGDi+BEVlEDkDy3lHHjwNOutyTiIisxwBE6nJrtZ90770o9PSEpqAASE52cKOIiFRErwdYKWEAIpWRR4BatkS2vPqLZTAiosplZQEvvwx4ewN16wLdugGjRgFz5gBr1wKHDgHXrzu6ldVGEXOAiMwiScUBqEULZDdtCr/jx4E//gD+7/8c3DgiIoUqKgKWLwdmzgQyM8V9N24Av/8uPm7XqBHQunXpj5YtAQ+P6m27HTEAkXpkZIiLoGo0QPPmyGreXNzPESAiorJt2QK89BLw11/i6+Bg4J13RJhJTgb+/tv0c2YmcOGC+LhtERI0GiAoSIShdu2ALl2AsDAgJARwNTNOSBLw77/AyZNAgwaAA/dxYwAi9ZCXwAcFATodsps2FV8zABERmTp2DJg2TQQgALjjDmD2bOCZZwB5s8Bb28eYuHJFhKGTJ0t/ZGcDqaniY9u24ud4eAChoSIMde0qPjdpApw9K84lf5w8KT5fvSqeN3cuMH26ffuhAgxApB7y5U5atgSA4gB08aL4q8Xf30ENIyJSiMxMdIyLg+vWrYDBIMLOc8+JoOHrW/nz77gDuOsu8VGSJAGXLxeHoSNHgIMHgaQkICcHSEwUH+YKCjJ/1MhOGIBIPeQRoFsBSO/pCallS2hOnxajQPfe68DGERHZgCSJUpOl9Hpg+XK4vvYamssjLA89BLz9tihZVZVGA9SvLz569Ci+32AQf5wePFj8kZQkRovq1QPatCn+aN1afG7ZErDThcYtwQBE6nFbAAIAqX17EYD++IMBiIjU7fp1YNAgUSZ66ilg4kQxUlKZxETg2WeBpCRoAGQ1a4Zay5fDVd4vzZ602uKA89hj4j6DAcjLA2rXtv/rVwGXwZN6yAGoVSvjXVLHjuIG5wERkZoVFQEjRwIJCWLBR2ws0Lw58Mgj4r6y9u25fBl4+mlRrkpKAurUgf6997Dr3Xch9e5d/e9BptUqPvwADECkJmWNAHXoIG4wABGRWkkSMGkSsHkz4OkJLFkC9O0rylrffgv07CkmFq9aBdy8Ke5ftkys6FqxQpxj7FggORmGSZMgubg49O2oBQMQqUN2tvhrBzANQPII0LFjJleJJyJSjbffBj75RMyzWbMGeP55YPt28YfduHEiFB06BERFiZJYp06i5HX1qrj9228iHN26iDiZhwGI1EEe/fH3B3x8iu9v1kwMtebni7o5EZGarFkjlqsDYuRn6NDixzp0EMHo/HkRkpo0EStejx4F6tQBPvxQbGR4992OabvKMQCpzV9/FS8HdyZllL8AiFqzPAr0xx/V2yYioqr43/+AJ54Qt198USxXL4ufn7iExenTwHffif18/v5blM1Y7rIaA5Ca3LgBhIeLtG8wOLo11au8AAQUByDOAyIitThxAhg2DCgoAIYPBxYurPw5rq7i2JkzxXJ0qhIGIDXJyhLLJC9fFpeEcCZlrAAz4ggQEalJejoweLCYw3PXXcDq1WI0m6oV9wFSk/z84tu5ueKKvs6iohGg0FDxmSNARORIe/eKi466uool7M2bAy1aiM/+/mKSc24u8OCD4jIRLVsCmzaJSc5U7RiA1KRkALp+3XHtcITbLoNhQl4Kf+GCuMien1/1tYuIaO9eMS/nl1/KP6ZWLRGEDAYxl/OOO8Sy93r1qq+dZIIBSE0KCopvO1MAys8XqyCAsgOQt7f4K+vMGTEK1Ldv9baPiJzTvn3AG28UBx8XF2DMGLFU/ezZ4o+LF8XIz9Gj4jidToz8tGnjsKYTA5C6OOsIUEqK2CisVq3y97no2JEBiIiqx759YsRHvtK6i4tYzfXaa+KPsdvl5wPnzokwlJICdO4MdO9enS2mMjAAqcntc4CcRcn5P+VdJDA0FNiwgROhich+/vwTeOUV0+Azdizw+utlBx+ZTld8vSxSDAYgNXHWElhFE6BlXApPRPZy7Rowa5bYeNBgMD/4kKIxAKmJs5bAKpoALZMD0NGj4pIYrvzWJqIqkiTgyy+BqVPFBUoB4D//AebPr/j/I1IFbjygJs4agMwZAWrRQswRys8HTp6snnYRUc31xx/iIqRjx4rwExwMxMeLi5My/NQIDEBqwjlA5R+j1RYvh2cZjIisde2auBhply7iIqO1aonrcP35JxAZ6ejWkQ0xAKmJM84BMhjEygmg7F2gS5I3RLTFROjCQnHpESJyDpIEfP21GOn54APxf88jj4hLVrz8MuDu7ugWko0xAKmJM5bALlwQ79vVVeytURFbTYQuKgLuvRdo1Ejs30FENVt6OjBiBDBqlCh3tW0ryl3r1gGNGzu6dWQnDEBq4owlMLn81axZ5RObbTUCtGwZkJAgrtPz7bdVOxcRKds33wB33gmsXw+4uQFz5oj/Q1juqvEYgNTEGUtg5qwAk7VvLz7/8w9w5Yp1r5eeDkyfXvz1999bdx4l+Phj8Zcs50QRlZaZKUpcI0eKS+iEhgIHDgAzZrDc5SQYgNTEGUtg5kyAltWpI0aKAOt/6b/8MpCdLeYBAMDu3SIUqY3BIP6STU4WEzolydEtIlKO9evFqM+334o9fWbOBPbvLx5FJqfAAKQmDECVq8qV4XfvBr74Quw2/cUXQNeuIjhs2mT5uRxt797i+Uu7dgE//eTY9pBz0+vFiOSIEcAzzwBz5wKffSbm2Rw/Lv7oqA7//ivm+QwfLub6tG8vgs/s2Rz1cULcLU5NSpbAnG0OUGUrwGQdOwIbN1oegIqKgEmTxO2nnxbX6Rk+HPj9d1EGGzfOsvM5mjx3ydNTrGZ75RXgvvu4QSRVv4QEIDq68rl53t5wbdIErTt1AiIigPr1bfP6kgT873/AypXAf/8L5OWJbTNefVWM/Oh0tnkdUh2OAKmJs40ASZL1I0CWToReuhQ4cgS44w7grbfEfQ89JD5v2yb2BlELg0H8Rw8AcXGAnx/w11/AqlUObRY5mYsXgdGjxWaCf/wB+PqKkZY33hB/ZNx3nxiBqVtXHJ+TA82xYwj56iu4tmgBvPCCuICotc6fB+bNA1q3Bvr0EaO6eXnij6R9+4A332T4cXL8c1BNnC0A/fsvkJUlbpt7vZ2Sl8TQ60V9vzKXLom/BAEgNhbw9xe327YF2rUTQ/Q//SSGztVg3z6xfYC3t5jkefWq+GUycybw2GNiYzcieykoAJYsEXPQrl8XJeVx40TgkH+2bnf9OnDhAooSEpA7bx7qpKSIc3z4oZikPHUq0KlT5a9986YoWa9cCWzdWjz3zdsbePRRICoKuOuu8i+qTE6FAUhNnK0EJo/+NGwoSjnmaNkS8PISf+mdPClCTGXkic/dugFPPWX62PDh4j/u9evVE4Dk8teDDwIeHsDEicD77wNnzgDvvWe6yo3IlrZuFZPuk5PF13fdJTYV7Nq14ufVrg0EB0Nq0QI7/fxwv7s7XBctEqOvX38tPiIjgSlTxP5cqalidCg11fTjwgXxh4+sTx8RekaMYPCnUhiA1MTZRoAsLX8BxZfESEwU84AqC0D/+x+werX4i3Dp0tIjRnIA+vlnEaq8vCx7D9WtZPnr4YfFZ3d3UdZ79FGxpf/48babX0Eke+EFMWoDiO+vt98GxowRP5OW0Ggg9e8PDB4MJCUBCxeKvXp+/VV8VKZxY+CJJ8QHr9lFFeAcIDUpGYBu3hQTd2sySydAy+QyWGXzgAoLiyc+jx8vRoBu17kz0LSpCD9bt1rWDkdITBT7INWuDQwcWHz/ww+L93f9uihNENnSpUvF4efFF4G//xYBxNLwc7suXcToz6lTwOTJYqsLPz/xczl0KPDcc8A774gdm/fuFSNA586JVWYMP1QJjgCpSckSGCDKYHXqOKYt1cGaESCgeCL0V1+JCZYPPCBGgm6v+3/4oZgr5OcnRnnKotGIUaD33hOrwYYNs6wt1a1k+atk2VCrBRYsAPr2FcuRn38eaNPGMW2kmmfjRvE5PBxYtMj252/WDFi8WPwccv4O2QhHgNSk5AgQUPPnAVmyC3RJffqILe3PnRPze0JCxDmeew745RcxenbxIjBrljh+/nwRgsozfLj4/MMPpUOokpRV/iqpTx8RBouKgNdeq9amUQ0n75gur5y0F4YfsiEGIDW5PQDV9HlA1o4A3XmnCE8ffCCW2up04oryH34ovvbzE0tzc3LEfj9PPlnx+SIigIAAsRR+505r3kn12L9fLP2tXVu8z7LMny9Gg777TpQMiKrq6lVgxw5x294BiMiGGIDU5PbRB6UGoKQkse9MVeTmAmlp4rY1tfwmTcTmaz//LJbTb9wo5vk0aiTm85w5I/6a/OijyucpuLiI+QaAsq8NJpe/Hnig/FVzd95ZHPimTuUlMqjqfvpJjCqGhLCsSqrCAKQmahgBun4d6NVLTLiVL8VgjTNnxOe6dcXmhFVRqxYwZIiY+3L+PHDokFih8t13QFiYeeeQy2AbNpgus63I7f9e9iRJFZe/Spo9WwSk336DRo2X+SBlWb9efJZ/RohUggFITdQwBygjQ7QrL0/swmota1eAVUajERuqvfyyZcP1ffuKCefp6WKjwcp8+KFYMv/ee1Y3FWfOiFUt5ti/X+yDUqsWMGhQxcc2bAjExAAAXF57DZqavpqQ7CcvT4yyAix/keowAKmJGkpgJS9quHx58UiOpayd/2Mv7u5iZRVQeRls0yaxyspgAGbMKC7lWeLkSXGZgPbtxZLiyphT/irp5ZcBf39oTp5Ek23bLG8fESC2hrhxQ2wV0bmzo1tDZBEGIDWRR4B8fMRnpQegoiJx3R9rWLsCzJ7kIf7vvy9/7kxSkrjchCSJXZhzc4tXm1kiJkb8Yrl2TZTv5EuClMWS8pfMx8e4EqzZli2Wt48IKC5/DRvGFVqkOgxAaiIHIHlOjBJLYHIAktu4ejVw7Jjl51HaCBAgNhb09ARSUoDDh0s//s8/YpQoLw8YMADYvFnc/+mnlk0K//ln4McfxZXbGzQQlxV47LHy5x4dOCCW/Ht5VV7+KmnMGEju7qh79mzZ74eoIoWFYmsIgOUvUiUGIDWRS2DynjVKHgHq3Flcf0eSRBnIUkoMQCUDxu1lsJwcUX66eFGstPrmGzFvaNgwUQp7+WXzXqOgQFxSABA73/74owhdP/9c/t49Jctfllyqw88P0gMPAAC0q1eb/zwiANi1SyyBr1cPuOceR7eGyGIMQGpy+wiQkgOQj4+45IJWK4bJDxww/xyFhWJEA7D9JOiqkstg8tA/IEZmHntMXHqjfn2xLFjeofvtt8VIzk8/Adu3V37+998Xc34CAsTV27t0AT77TDy2YIHY3bokSSoOQOaWv0owjBkDANB+/bWyN3kk5ZF/BoYMKX0NPSIVYABSE7UFoJAQ4PHHxdeWXIE8NVWECg8PUQJSkvvvF4Hm2LHiK17HxIiA4+EhJkA3bVp8fJs2wDPPiNtTpojRoPKkpRVfpys2tniu18iRwLRp4vZTT5mGyd9/Ly5/DR5s8duRBgzAzbp1ocnMLF7NQ1QZg0FsCQGw/EWqxQCkJnIAkktgSpwDJE/WlX95z5olLkuxdav5uyjLE6BbtKj6xRRtrW5doF8/cXv9erHc/f33xddffimuhXS7WbMAb2+x/9DXX5d/7mnTRCmtWzdg7FjTx+bNE/OL8vNFWe3SJXG/PPpz//3WXane1RXn+/QRt1etsvz55JwOHBDl3tq1i38eiFRGYb9dqFx6ffEkWLWMAAFA8+ZiB2YAeP1183YeVuL8n5LkMtj774t5OoC4xMR//lP28fXqFc/fee01sbrrdomJxQHkgw9KBz+tVkwoDwkRv3geekhc06wK5S/Z+b59xY0ffwQuX7b6PORE5PLX/feLkU8iFWIAUouS8zPUEIBKXqX+9dfFRN49e4pXRlVEiUvgSxo6VCz5vXRJlAKeeqrySc6TJwNBQWInannESGYwiAu1AsATT5Q9igSIULlxI+DrKwLTgAFiRZqnp1XlL1lO06YwhIWJbQvWrLH6POQkJKn6Ln5KZEcMQGpRchdoNawCk0eAADGP5/nnxe3XXy9/HszVq2IF1AcfiK/btbNbM6skIEBcTBUQw//LllW+B4qnJ/Dmm+L2W2+ZjrR88YUoKXh7i7k/FWnVSqwwc3EBdu8W9z3wgNgBugqkW5OhWQajSv31l9io093dsm0XiBSGAUgtSo4A+fqKz0qcA1RWAALECImPj1gpJZdtZHo9EBcHtG4NLFkiRiKGDgXkX8pKFBcn5uV8952Y42SOUaPE9gDZ2cDcueK+7Gzg1VfF7ZkzgcDAys8TGQm8+27x11Uof8kMjzwi3sehQ+LfiKg8cvkrMrL0zzmRijAAqYU8AuTuLiYeAuoZAQJE2W7KFHF7xgwRcgBgxw6x1HviRHHV9pAQ4JdfxAoTJc8taNdOjGaVLPVVRqsFFi4Ut5ctE8vd584V1xdr06Z4lMwczz8vJlc/+qhYhlxVfn7F5/n886qfj2ouOQCx/EUqxwCkFnIA0unUGYAAUd7y9xfD52+9JSYN33sv8OefYnXV+++LHYkHDKjGBleze+8VE0eLioCoKGDxYnH/4sUi3JpLoxGXGVmzRnxP2MITT4jPq1eLvZiIbpeSIi73otXaJngTORADkFrIJbCSAUiJJbDbl8GX5O1dvBpq1ixRPtJqgUmTxMTn554zv5ykZgsWiPe9Z48IQg88oIy5FAMHivlNly9zT6CSjh4V87cyMx3dEseT9/655x6x6SeRijEAqUXJEpg84VVtI0CAKHU1ayZu33uvGPH58MPiid3OICQEePppcdvdHXjvPce2R+bmBoweLW5zMrSQni4muk+fLuZv7d3r6BY5FstfVIMwAKlFWSWwggJlXb6gsLB4j5vy5sZ4eIiRj8RE4NdfgQ4dqq99SjJvnighfPihsi73IW/A+MMP3BNIkkSZMiNDfP3PP0CvXiKwmrOfVU2TkQEkJIjbw4Y5tClEtsAApBZllcAAZZXBcnKKb3t7l39cgwZA9+6VLx2vyerVE3v6jBvn6JaY6tAB4J5AwgcfiFKgTidC+yOPiH6JiREX+r12zdEtrF6bNoktLDp3Lh7FJVIxBiC1KFkCc3cvniujpAAkl788PZ1jLk9NJU+GduYy2J9/AlOnitvvvgtERABr14oROzc3UQoKCxPbBtQUFy4Ax4+LRQopKWLEKy1NrM7Myire/FDeCZ1I5RiA1KJkCQxQ5jygyub/kDo89phz7wmUlyf6oKBATFB/9llxv0YjJuz/9psYATlzRgSjTz5Rf0lswwagSRMxP61NG3EJm6AgMVrr7y9WacoT4zn/h2oIBiC1KFkCA5S5FJ4BqGZw9j2BpkwRux0HBgIrV5Yu1XbrJpaCyxenfeYZuERFweXmTce0t6pOnxZzvwwG8bPr41P+KG6/fiIkEdUAighAS5cuRbNmzeDh4YHw8HDs37+/3GNXrVoFjUZj8uFx24Z5kiRh5syZaNCgATw9PREZGYmTJ0/a+23YV8kSGMAARPblrHsCbdwoNqkExCVK6tUr+zhfX3HsggWAiwu0X3+N7rGx6uurGzfEflzZ2WJpe2amKHfl5Yk/ugwGMe/pxg0xxy8+3rnn7lGN4vAAtG7dOsTExGDWrFlISkpCaGgoBg4ciAx55UUZfHx8cOnSJePHuXPnTB5fsGAB3n//fcTFxSExMRG1atXCwIEDcVOtf6EBpUtgStwLqKI9gEhdSu4JtGWLo1tTPkkSpZkLF6p+rgsXgCefFLenTAH696/4eI1GzBPavh1SrVqo/8cfcJkwofrLYRkZot3BwcC2bZY9d/JksRVFvXpijtPtoz4ajbjunIeH+D+H4YdqEIcHoEWLFmHcuHGIiopCSEgI4uLi4OXlhZUrV5b7HI1Gg8DAQONHQECA8TFJkrB48WJMnz4dQ4cORceOHfHFF1/g4sWL2CBv4qVGt5fAOAeI7KnknkCffurYtlRkwQJg8GBxOZUTJ6w/j8Egrj135Yo4l3zhWnP06gX9mjUwaLXQfvml2OSzOuj1YrQqOBj47DNxaZXBg4H//te853/5JbB8uQg1X38NNGpk3/YSKYyrI1+8oKAABw8exLRp04z3abVaREZGYm8FG45dv34dTZs2hcFgQJcuXfDWW2/hzjvvBACcPXsWaWlpiIyMNB5fp04dhIeHY+/evXj00UdLnS8/Px/5Ja62nn3rF3lhYSEKbTykLZ/P0vNq8/LgAsDg5gZ9YSFcatWCFkBRVhYkhQy7a69eFW309obezm2yth/JVIX9OHYsXBctgmbTJhQeOgS0b1/NravE4cNwnTEDGgDIyIDUrx+Ktm0DWra0+FTahQvhsn07JC8vFH3+uQgFFnxvFfbrh+SJE9F56VJg7lwUNWoESR5NsgPN779D+9xz0B48CACQOnWC1LAhtJs3Q3rkEeiXLoUkb7ZZlmPH4DphAjQA9NOnw9C7tyLKd/y5rjpn70NL3rdDA1BmZib0er3JCA4ABAQE4EQ5f80FBwdj5cqV6NixI7KysrBw4ULcfffdOHbsGBo3boy0tDTjOW4/p/zY7WJjYzF79uxS92/duhVeXl7WvLVKxcfHW3R8yz/+QHsAFy5fRtLmzQjLzkZjAMcPHMCZ296ro7RNSkIwgJQrV3Bk8+ZqeU1L+5HKVl4/do2IQKM9e5A+eTIOvvRSNbeqfNqCAvSeMgU+hYVI79IFnpmZ8ElNRWGvXtj91lu4Wd7cnTLUPXUKPWfMAAAcjopC6unTYmKwpfr3h9flywj+5hton30WiRcuICMszPLzVMDt+nW0W70azX75BRpJQqGXF46PHo2zAwcCAEILC9EsPh6uzz6Lv/bswckRI0qVrVxu3EDvqVPhnZeHjNBQ7O3UCaimn1dz8ee66py1D/Py8sw+1qEByBoRERGIiIgwfn333XejXbt2+PjjjzF37lyrzjlt2jTExMQYv87OzkZQUBAGDBgAHxuXcwoLCxEfH4/+/fvDzYK9crR//gkAaNSiBQIHD4bLhg1AQgJCmjRB28GDbdpGa2l//RUA0LRDBwTZuU3W9iOZqrQfGzcGunZFo4QEBCxdCrRtW/2NLIN26lS4pKZCCgjAHT/8AOj1kO69F16nTmHA22+LkaAGDSo+iSRB8913cFmwABq9Hobhw9F+0SK0t2Kei9yPQStXwqDTQfvll7hr0SLRji5drHyXt7V19Wq4vPoqNLd26Db83/8B8+ejXWAg2snHPfAA9DNmwGXBAoSsXo1gPz8Y3n5bXHvu1nlcxoyB9p9/IDVqBN/NmzHYgrBob/y5rjpn70O5gmMOhwYgf39/uLi4ID093eT+9PR0BAYGmnUONzc3dO7cGadOnQIA4/PS09PRoMR/gOnp6ejUqVOZ59DpdNCVcUVtNzc3u30DWXzuoiIAgNbTE1o3N+M8G5cbN+CilG/yW/ORXHx9q61N9vw3cibl9mNYGDBsGDQbNsBtwQIxb8TRtm0DliwBAGhWrIBbw4bi/u3bgZ49oTl1Cm6DBgE7d5a/iuvCBbGnz8aN4usOHaD99FNo5VWWVnJzd4d2xQogLQ2a+Hi4DR0qrh/WvLn1J83IAEaNEpeOAYB27YCPPoK2T5+yJ3G+/baYwP7SS3BZsgQuV64AK1aIeV3LlgHr1gEuLtCsW1fcdwrDn+uqc9Y+tGhgwY7tqJS7uzvCwsKwrcTKBYPBgG3btpmM8lREr9fjyJEjxrDTvHlzBAYGmpwzOzsbiYmJZp9TkbgMnhxl+nTx+euvgVt/aDjM1avFS/SfeQa4//7ix4KCRAhq2FDs4zNggDi+JINBbFwYEiLCj6srMGMGcOCAWNpuC25uYiJyaKi4mOqgQWJytTX27xch9Ndfxd488+eLVVt9+lT8vJgYsYeTi4sIrcOHA7t3Ay+8IB5/+22gRw/r2kRUQzh8FVhMTAyWL1+Ozz//HMePH8fEiRORm5uLqKgoAMCYMWNMJknPmTMHW7duxZkzZ5CUlITRo0fj3LlzePrWhD+NRoMXXngB8+bNw6ZNm3DkyBGMGTMGDRs2xDA1X8CvvI0QuQye7C0sTAQNgwF46y3HtiU6WlyioVUrYOHC0o+3aCFGiOrXF0Fh0KDia9SdPAnce68ITtnZ4np0SUnAnDnFP1e24uMD/PSTCGXJyWJjSUu34fj0U6BnT/F+27QBfv8deOWV4j+CKjNmjLhkh4cH8OOPQO/e4v+RYcNEQCJycg4PQCNHjsTChQsxc+ZMdOrUCYcPH8aWLVuMk5hTU1Nx6dIl4/FXr17FuHHj0K5dOwwePBjZ2dnYs2cPQkrsTvryyy/jueeew/jx49GtWzdcv34dW7ZsKbVhoqrwUhjkSLcmCePLL4GzZx3ThrVrxSiUi4vYoLHkRYFLattWbNh3xx1AYqK4nMX8+UDHjsCuXYCXF7BokbjAaYcO9mtvo0Zij6I6dcTlM8LDxfXVKgtC+fnA+PHiQrkFBcDQoWIkyJodmB98ENi6VfxMSpIIiJ99xv18iABAolKysrIkAFJWVpbNz11QUCBt2LBBKigosOyJTz0lSYAkvfmm+HrFCvH14ME2b6PVgoNFm3butPtLWd2PZMKifhwwQPz7jh9v/gv8+68knTxpfQNl589LUt264vVnzjTvOQcOSJKPj3iO/BEZKUlnzlS9PbepsB937JCk2rWL21C/viTNmCFJFy+WPjY1VZK6dRPHaTTi512vr3oDjxyRpOefl6QTJ6p+Ljviz3XVOXsfWvL72+EjQGQmNV0LrE4dx7aD7EMeBfrsMyA1tfLjk5KA1q1F+ebbb61/XYNBzPu5dk1ch0uek1SZrl3F8m5vbzG/57PPxGhIVSYkW6NPH3F19fnzRUksIwOYOxdo2lRsNnnggDhuxw5RbjxwQIxe/fwz8NprxSu4qqJ9ezFxPDi46uciqiEYgNRCDZfCYAmsZrvnHqBvX7Fh3oIFFR+bmCjm21y5IsY9Sq5istSHH4p5PZ6eogRnycqWHj1E+Dh/XoQoR5V+/PzE/J0zZ4BvvhHtKiwEvvpKzEXq3BmIjBSXHunUScz3ubW3DxHZBwOQWty+Ckxpc4D0+uIwxgBUc8mjQJ9+Cly8WPYxu3eLX+ZZWeIX/YgR4pf9sGHFox3mOnhQBAdATHq2ZgTjjjuKf14czdUVePhhICFBhJzHHxeB7vDh4stx7NlT/aNURE6IAUgtyhsBUkoAklfaAKLkQDVTnz5iJCg/H3jnndKPb9sG3Hef+L7s21dcSPWrr0Qgys0Vq7LMvWbXqlXitW7eFOecONGW78TxwsLEFedTU8Wy9NWrxXv29HR0y4icAgOQWih9Gbxc/tLpbL+kmJRDoykeBYqLA0peXmbzZrFcPi9PBJaffhLfpzod8P33Yv7Ov/+K/XnOny//NW7cECugoqJE+Bk0SKz+qqkrlwIDgZdfFmXCmvoeiRSIAUgtKiqBSZJj2lQS9wByHv37iyXdN28C774r7tuwQZS48vPFsu0NG0xHMry9RUAKDhbhZ+BAEYZud+aMKJt9+qkIA3Pnij1sbLVJIRHRLQxAalFeCayoqHh0yJE4Adp5lBwF+ugj8fGf/4h5Po88IlZ8lTUK6O8vVmE1bgwcPy5Gi0qWcDdtEtfNOnSo+Njp022zCoqI6Db8n0Utbi+BlZzUqYR5QAxAzmXwYBFW8vLENbX0ejGh96uvKl6l1aSJCDbyJoUjRoiS17RpYuQoKwuIiBAhKDKy+t4PETkdBiC1uL0E5uZWHIaUMA+IewA5l5KjQICYs7NqlVjlVJl27UQ5rFYtEYaaNBF75ADA5MniIqaNG9uj1URERg69GjxZ4PYSGCB+geTncwSIHGPIEOD110U59pVXLJvAGx4uJkY/8ACQmSnOsWKFKKEREVUDBiC1uL0EBohfGleuMACRY2i1wLx51j9/wABxRfZ164BXXxXX8CIiqiYMQGpxewkMUNZeQAxAZI1Bg8QHEVE14xwgtSirBKakvYC4DJ6IiFSEAUgtyiqBKelyGBwBIiIiFWEAUgNJKg5ALIERERFVGQOQGpTc6FCpJTAugyciIhVhAFKD8gIQS2BERERWYQBSA3kCNMASGBERkQ0wAKmBHIBcXU2vi8QAREREZBUGIDUoawUYoMw5QAxARESkAgxAalDWJoiAcuYA6fVATo64zQBEREQqwACkBmVtgggopwRW8vUZgIiISAUYgNRA6SUwufxV8gr1RERECsYApAZKHwEquQeQJVcEJyIichAGIDVQ+hwgToAmIiKVYQBSg8pKYAxAREREFmEAUoPKSmBKmQPEAERERCrBAKQG5ZXASo4ASVL1tqmkrCzxmQGIiIhUggFIDcobAZLnABkMwM2b1dumkjgCREREKsMApAblzQGSAxDg2HlADEBERKQyDEBqUF4JzMUF8PQUtx05D4gBiIiIVIYBSA3KK4EBylgKX3IfICIiIhVgAFKD8kpggDKWwnMEiIiIVIYBSA3KK4EBylgKzwBEREQqwwCkBhWVwDgCREREZDEGIDWoqASmhDlA3AeIiIhUhgFIDcwpgXEEiIiIyGwMQGpgTgmMc4CIiIjMxgCkBkpeBWYwADk54jaXwRMRkUowAKlBRSUwR88Bys0tvg4ZR4CIiEglGIDUQMmrwOTyl6sr4OHhmDYQERFZiAFIDcwpgTlqDlDJ+T8ajWPaQEREZCEGIDVQcgmMS+CJiEiFGIDUQA0lMAYgIiJSEQYgNVBLCYyIiEglGIDUQMkbITIAERGRCjEAqUFFJTBHzwGSAxD3ACIiIhVhAFIDJW+EyBEgIiJSIQYgNTCnBMY5QERERGZjAFIDc68FZjBUX5tkDEBERKRCDEBqUFEJTJ4DJEnAjRvV1yYZ9wEiIiIVYgBSg4pGgLy8im87Yh4QR4CIiEiFGICUTpIqngOk1RaPAjliHhADEBERqRADkNLp9cVXWy9rBAhw7EowBiAiIlIhBiClk0d/gPIDkCP3AuI+QEREpEIMQEpXMgCVVQIDHLsUniNARESkQgxASicHIK0WcHUt+xhHlcAkiQGIiIhUiQFI6SpaAi9zVAksL6947yEGICIiUhEGIKWraAWYzFEjQPIeQFqt6XJ8IiIihWMAUrqK9gCSOWoOUMnyl0ZTva9NRERUBQxASmdOCcxRI0Cc/0NERCrFAKR05pTAHDUHiAGIiIhUyuEBaOnSpWjWrBk8PDwQHh6O/fv3m/W8tWvXQqPRYNiwYSb3X79+HdHR0WjcuDE8PT0REhKCuLg4O7S8mlhSAnNUAOIeQEREpDIODUDr1q1DTEwMZs2ahaSkJISGhmLgwIHIyMio8HkpKSmYMmUKevbsWeqxmJgYbNmyBatXr8bx48fxwgsvIDo6Gps2bbLX27AvS0pgjpwDREREpCIODUCLFi3CuHHjEBUVZRyp8fLywsqVK8t9jl6vx6hRozB79my0aNGi1ON79uzB2LFj0adPHzRr1gzjx49HaGio2SNLiqPkVWAMQEREpFLl7KxXWkxMjNknXbRoUaXHFBQU4ODBg5g2bZrxPq1Wi8jISOzdu7fc582ZMwf169fHU089hd27d5d6/O6778amTZvw5JNPomHDhti5cyf+/vtvvPfee+WeMz8/H/kldlzOvvWLvbCwEIWFhZW+F0vI5zP3vJrcXLgCMLi7Q1/OczQ6nTgmJ6fcY+xBe+UKXAAYateu1tcFLO9HKhv70TbYj7bBfqw6Z+9DS9632QHo0KFDJl8nJSWhqKgIwcHBAIC///4bLi4uCAsLM+t8mZmZ0Ov1CAgIMLk/ICAAJ06cKPM5CQkJWLFiBQ4fPlzueT/44AOMHz8ejRs3hqurK7RaLZYvX45evXqV+5zY2FjMnj271P1bt26Fl532t4mPjzfruMYHDiAMQGZ2NvZu3lzmMYHJyQgHcO2ff7C7nGPsIeSPP9AawJnMTByrxtctydx+pIqxH22D/Wgb7Meqc9Y+zMvLM/tYswPQjh07jLcXLVoEb29vfP755/D19QUAXL16FVFRUWXOy7GFnJwcPP7441i+fDn8/f3LPe6DDz7Avn37sGnTJjRt2hT/+9//MGnSJDRs2BCRkZFlPmfatGkmI1zZ2dkICgrCgAED4GPj8k5hYSHi4+PRv39/uLm5VXq85tZ8KP9GjTB48OCyj9HpgPnz4evmVu4x9qD98UcAQPPQUDStxtcFLO9HKhv70TbYj7bBfqw6Z+9DuYJjDrMDUEnvvvsutm7dagw/AODr64t58+ZhwIABeOmllyo9h7+/P1xcXJCenm5yf3p6OgIDA0sdf/r0aaSkpODBBx803me4dRkGV1dXJCcno2HDhnjttdewfv163H///QCAjh074vDhw1i4cGG5AUin00FXxiRjNzc3u30DmX3uoiIAgNbDA9ryjr+1CkuTm1u93/C35hy5+PrCxUE/aPb8N3Im7EfbYD/aBvux6py1Dy15z1ZNgs7Ozsbly5dL3X/58mXk5OSYdQ53d3eEhYVh27ZtxvsMBgO2bduGiIiIUse3bdsWR44cweHDh40fQ4YMQd++fXH48GEEBQUZ5+xotaZvy8XFxRiWVEcNGyFyGTwREamMVSNADz30EKKiovDuu++ie/fuAIDExERMnToVw4cPN/s8MTExGDt2LLp27Yru3btj8eLFyM3NRVRUFABgzJgxaNSoEWJjY+Hh4YH27dubPL9u3boAYLzf3d0dvXv3xtSpU+Hp6YmmTZti165d+OKLL8yamK1IlqwC4zJ4IiIis1gVgOLi4jBlyhT83//9n3HGtaurK5566im88847Zp9n5MiRuHz5MmbOnIm0tDR06tQJW7ZsMU6MTk1NLTWaU5m1a9di2rRpGDVqFK5cuYKmTZvizTffxIQJEyw6j2JYshFiXh6g1wMuLvZvF8AAREREqmVxANLr9fj999/x5ptv4p133sHp06cBAC1btkQt+ZIMFoiOjkZ0dHSZj+3cubPC565atarUfYGBgfjss88sbodimVMCK9nveXmAt7d92yRjACIiIpWyOAC5uLhgwIABOH78OJo3b46OHTvao10kM6cE5ukprsYuSaIMVl0BKCtLfGYAIiIilbFqEnT79u1x5swZW7eFymJOCUyjqf6J0JLEESAiIlItqwLQvHnzMGXKFPz444+4dOkSsrOzTT7IhswpgQHVH4Bu3BDzjQAGICIiUh2rJkHLm+0NGTIEGo3GeL8kSdBoNNDLvxip6swpgQHF84CqKwDJQVejMZ2DREREpAJWBaCSu0KTnZlTAgOqfyl8yfKXhSv1iIiIHM2qANS7d29bt4PKo9QSGOf/EBGRilkVgGR5eXlITU1FgfxL+hauDLMhpZfAGICIiEiFrApAly9fRlRUFH7++ecyH+ccIBuytARWXQGIS+CJiEjFrJq88cILL+DatWtITEyEp6cntmzZgs8//xytW7fGpk2bbN1G52ZpCcwRc4CIiIhUxqoRoO3bt2Pjxo3o2rUrtFotmjZtiv79+8PHxwexsbHGK7GTDSh1BIgBiIiIVMyqEaDc3FzUr18fAODr62u8MnyHDh2QlJRku9YR5wARERHZgVUBKDg4GMnJyQCA0NBQfPzxx7hw4QLi4uLQoEEDmzbQ6alhGTwREZHKWFUCmzx5Mi5dugQAmDVrFu677z589dVXcHd3L/MCpVQFSl8GX6dO9bweERGRDVkVgEaPHm28HRYWhnPnzuHEiRNo0qQJ/P39bdY4gvklMM4BIiIiMptVJbDbL4Tq5eWFLl26MPzYg7klMM4BIiIiMptVI0CtWrVC48aN0bt3b/Tp0we9e/dGq1atbN02ApS7DJ77ABERkYpZNQJ0/vx5xMbGwtPTEwsWLECbNm3QuHFjjBo1Cp9++qmt2+jcWAIjIiKyOasCUKNGjTBq1Ch88sknSE5ORnJyMiIjI/HNN9/gmWeesXUbnRv3ASIiIrI5q0pgeXl5SEhIwM6dO7Fz504cOnQIbdu2RXR0NPr06WPjJjoxvV58AJwDREREZENWBaC6devC19cXo0aNwquvvoqePXvC19fX1m2jkheZNbcEVh1zgCSJy+CJiEjVrApAgwcPRkJCAtauXYu0tDSkpaWhT58+aNOmja3b59zk8hdgfgns5k2gqAhwteqf1vx2FRaK2xwBIiIiFbJqDtCGDRuQmZmJLVu2ICIiAlu3bkXPnj2Nc4PIRkqOALm5VXysXAID7D8KJI/+AMXBi4iISEWsCkCyDh06oEePHoiIiEC3bt2QkZGBdevW2aptVHIFmEZT8bE6HeDiIm7bOwDJS+C9vQFtlb6FiIiIHMKq316LFi3CkCFD4Ofnh/DwcKxZswZt2rTBd999Z7wwKtmAuSvAABGQqmslGCdAExGRylk1UWTNmjXo3bs3xo8fj549e6IOJ8Lah7mbIMpq1xajMwxAREREFbIqAB04cMDW7aCymLsJoqy6lsIzABERkcpZPYFj9+7dGD16NCIiInDhwgUAwJdffomEhASbNc7pWVICA6pvKTwDEBERqZxVAei7777DwIED4enpiUOHDiH/1i/qrKwsvPXWWzZtoFOzpgQGVN8IEEufRESkUlYFoHnz5iEuLg7Lly+HW4nl2T169EBSUpLNGuf0LC2BcRI0ERGRWawKQMnJyejVq1ep++vUqYNr165VtU0ks7QExjlAREREZrEqAAUGBuLUqVOl7k9ISECLFi2q3Ci6xdoSWHXtA8QAREREKmVVABo3bhwmT56MxMREaDQaXLx4EV999RVeeuklTJw40dZtdF4sgREREdmFVcvgX331VRgMBvTr1w95eXno1asXdDodpk6diqefftrWbXReLIERERHZhVUjQBqNBq+//jquXLmCo0ePYt++fbh8+TLq1KmD5s2b27qNzkupJTAGICIiUjmLAlB+fj6mTZuGrl27okePHti8eTNCQkJw7NgxBAcHY8mSJXjxxRft1VbnwxIYERGRXVhUAps5cyY+/vhjREZGYs+ePXj44YcRFRWFffv24d1338XDDz8MF/mCnFR11m6EyH2AiIiIKmRRAPr222/xxRdfYMiQITh69Cg6duyIoqIi/PHHH9BUdrVyshznABEREdmFRSWwf/75B2FhYQCA9u3bQ6fT4cUXX2T4sRelzgHiMngiIlI5iwKQXq+He4n5KK6urqgt/9Il21PiHKD8/OJgxgBEREQqZVEJTJIkPPHEE9DdGpG4efMmJkyYgFpy6eWW77//3nYtdGZKnAMkl78AwNvbfq9DRERkRxYFoLFjx5p8PXr0aJs2hm5jaQmsOuYAyQGoVi2AE96JiEilLApAn332mb3aQWWxtgRmzzlAnABNREQ1gFUbIVI1sbYEVlBQPHpka1wCT0RENQADkJJZWwID7DcKtH+/+BwUZJ/zExERVQMGICWztATm7g64uYnb9gpA334rPj/0kH3OT0REVA0YgJTM0hIYYN+VYCkpwIEDgFYLDB9u+/MTERFVEwYgJbO0BAYUB6Br12zeHOPoT+/eQECA7c9PRERUTRiAlMzSEhgAtGghPv/9t+3bIweghx+2/bmJiIiqEQOQkllTAmvfXnw+etS2bWH5i4iIahAGICWzpgTWoYP4fOSIbdvy3/+Kzyx/ERFRDcAApGTWlMDsNQLE8hcREdUgDEBKZk0J7M47xed//rHdROiUFLH/D8tfRERUQzAAKZk1JbC6dYs3KbTVKJBc/urVi+UvIiKqERiAlMyaEhhg+zKYXP565BHbnI+IiMjBGICUzJoSGGDbAMTyFxER1UAMQEpmTQkMKF4JZosAxPIXERHVQAxASiVJxQHI2hLYkSPiPFXB1V9ERFQDMQAplRx+AMtHgNq2FSWrK1eAtDTr23DuHMtfRERUIzEAKVVVApCnJ9CqlbhdlTJYyfJXYKD15yEiIlIYBiClkidAA5aXwADb7Aj9zTfiM8tfRERUwzAAKZUcgFxdRQnKUlVdCSaXvzQalr+IiKjGYQBSKmtXgMmqGoBKXvuL5S8iIqphHB6Ali5dimbNmsHDwwPh4eHYv3+/Wc9bu3YtNBoNhg0bVuqx48ePY8iQIahTpw5q1aqFbt26ITU11cYttzNrN0GUySWwY8cAg8Hy53P1FxER1WAODUDr1q1DTEwMZs2ahaSkJISGhmLgwIHIyMio8HkpKSmYMmUKevbsWeqx06dP45577kHbtm2xc+dO/Pnnn5gxYwY8PDzs9Tbsw9pNEGUtW4rn5uUBZ89a9txz54DERJa/iIioxnJoAFq0aBHGjRuHqKgohISEIC4uDl5eXli5cmW5z9Hr9Rg1ahRmz56NFi1alHr89ddfx+DBg7FgwQJ07twZLVu2xJAhQ1C/fn17vhXbq2oAcnUF2rUTty0tg3H1FxER1XAOC0AFBQU4ePAgIiMjixuj1SIyMhJ79+4t93lz5sxB/fr18dRTT5V6zGAw4KeffkKbNm0wcOBA1K9fH+Hh4diwYYM93oJ9VXUOEGD9SjBe+4uIiGo4V0e9cGZmJvR6PQJuu7xCQEAATpw4UeZzEhISsGLFChw+fLjMxzMyMnD9+nXMnz8f8+bNw9tvv40tW7Zg+PDh2LFjB3r37l3m8/Lz85FfYtl5dnY2AKCwsBCFhYVWvLvyyeer7Lya3Fy4ApDc3FBkZRu07drBBYDhzz+hN/cc587BLTERkkaDogcfBGz8/m3F3H6kirEfbYP9aBvsx6pz9j605H07LABZKicnB48//jiWL18Of3//Mo8x3JrsO3ToULz44osAgE6dOmHPnj2Ii4srNwDFxsZi9uzZpe7funUrvLy8bPQOTMXHx1f4eP3ff0cEgKybN7Fr82arXqN+Xh4iAFxPTMQOM8/RcuNGtAfwb0gIfktKsup1q1Nl/UjmYT/aBvvRNtiPVeesfZiXl2f2sQ4LQP7+/nBxcUF6errJ/enp6QgsY97J6dOnkZKSggcffNB4nxx4XF1dkZycjKCgILi6uiIkJMTkue3atUNCQkK5bZk2bRpiYmKMX2dnZyMoKAgDBgyAj4+PVe+vPIWFhYiPj0f//v3h5uZW7nGaWynWp359DB482LoX69ABmDcP3hcvYnBkpFkrylwWLgQA+D79tPWvWw3M7UeqGPvRNtiPtsF+rDpn70O5gmMOhwUgd3d3hIWFYdu2bcal7AaDAdu2bUN0dHSp49u2bYsjt81lmT59OnJycrBkyRIEBQXB3d0d3bp1Q3Jysslxf//9N5o2bVpuW3Q6HXRlzLVxc3Oz2zdQpefW6wEAWp0OWmvb0Lw54OMDTXY23M6cKZ4TVJ6MDGDPHgCAy/DhcFHBD489/42cCfvRNtiPtsF+rDpn7UNL3rNDS2AxMTEYO3Ysunbtiu7du2Px4sXIzc1FVFQUAGDMmDFo1KgRYmNj4eHhgfby5n631K1bFwBM7p86dSpGjhyJXr16oW/fvtiyZQt++OEH7Ny5s7relm1UdRUYIJaxt28vQs3Ro5UHoB9/FHsGdekCNGli/esSEREpnEMD0MiRI3H58mXMnDkTaWlp6NSpE7Zs2WKcGJ2amgqthZeBeOihhxAXF4fY2Fg8//zzCA4OxnfffYd77rnHHm/BfmyxCgwQoUcOQJWRV8uVsbkkERFRTeLwSdDR0dFllrwAVDpqs2rVqjLvf/LJJ/Hkk09WsWUOVtWdoGXy6FhlS+FzcwF50hwDEBER1XAOvxQGlcMWJTDA/GuCbd0K3LwJtGhR/BwiIqIaigFIqWxVApPDzNmzwPXr5R9Xsvyl0VTtNYmIiBSOAUipbFUC8/cvvpzFsWNlH1NUBPzwg7jN8hcRETkBBiClslUJDKi8DLZ7N3D1qghLd99d9dcjIiJSOAYgpbJVCQwoXv5eXgCSy19DhgAuLlV/PSIiIoVjAFIqW5XAgIpXgkkSl78TEZHTYQBSquoqgR0+DKSmAl5eQGRk1V+LiIhIBRiAlMqWJbA77xSf09OBy5dNH5NHfwYOBDw9q/5aREREKsAApFS2LIHVqiX29wFKjwKx/EVERE6IAUipbFkCA8oug505A/z5p5j4fP/9tnkdIiIiFWAAUipblsCAsleCbdwoPvfqBfj52eZ1iIiIVIABSKlsWQIDyh4BYvmLiIiclMMvhkrlsGcJTJKAf/8FEhLEfUOH2uY1iIiIVIIBSKlsXQJr0wZwcwOys4Hz54Ht2wGDAejcGWja1DavQUREpBIsgSmVrUtg7u5AcLC4ffQoy19EROTUGICUytYlMKC4DJaYCGzdKm4zABERkRNiAFIqewQgeSXYsmXAjRtAs2bF9xERETkRBiClkucA2aoEBhSPAMm7QQ8bBmg0tjs/ERGRSjAAKZU9S2Aylr+IiMhJMQAplT0CULNm4rIYgNj4sEcP252biIhIRRiAlMoeJTCttvjCqA8+CLhyFwQiInJODEBKJEn2GQECgMceA2rXBiZMsO15iYiIVIQBSImKikQIAmwfgF54AcjJAcLDbXteIiIiFWEAUiK5/AXYPgARERERA5AiyeUvwLZzgIiIiAgAA5AyyQFIq+VEZSIiIjtgAFIiW18IlYiIiEwwACmRrS+ESkRERCYYgJTIXkvgiYiICAADkDKxBEZERGRXDEBKxBIYERGRXTEAKRFLYERERHbFAKRELIERERHZFQOQErEERkREZFcMQErEEhgREZFdMQApEUtgREREdsUApEQsgREREdkVA5ASsQRGRERkVwxASsQSGBERkV0xACkRS2BERER2xQCkRCyBERER2RUDkBKxBEZERGRXDEBKxBIYERGRXTEAKRFLYERERHbFAKREDEBERER2xQCkRPIcIJbAiIiI7IIBSIk4AkRERGRXDEBKxABERERkVwxASsQSGBERkV0xACkRR4CIiIjsigFIiRiAiIiI7IoBSIm4EzQREZFdMQApEXeCJiIisisGICViCYyIiMiuGICUiCUwIiIiu2IAUiKWwIiIiOyKAUiJWAIjIiKyKwYgJWIJjIiIyK4YgJSIJTAiIiK7YgBSIpbAiIiI7IoBSGn0evEBMAARERHZCQOQ0sjzfwCWwIiIiOyEAUhp5PIXwBEgIiIiO1FEAFq6dCmaNWsGDw8PhIeHY//+/WY9b+3atdBoNBg2bFi5x0yYMAEajQaLFy+2TWPtreQIkJub49pBRERUgzk8AK1btw4xMTGYNWsWkpKSEBoaioEDByIjI6PC56WkpGDKlCno2bNnucesX78e+/btQ8OGDW3dbPspuQJMo3FsW4iIiGoohwegRYsWYdy4cYiKikJISAji4uLg5eWFlStXlvscvV6PUaNGYfbs2WjRokWZx1y4cAHPPfccvvrqK7ipaSSFK8CIiIjsztWRL15QUICDBw9i2rRpxvu0Wi0iIyOxd+/ecp83Z84c1K9fH0899RR2795d6nGDwYDHH38cU6dOxZ133llpO/Lz85FfYu5NdnY2AKCwsBCFhYWWvKVKyecr97y5uXADIOl0KLLxa9cklfYjmYX9aBvsR9tgP1ads/ehJe/boQEoMzMTer0eAQEBJvcHBATgxIkTZT4nISEBK1aswOHDh8s979tvvw1XV1c8//zzZrUjNjYWs2fPLnX/1q1b4eXlZdY5LBUfH1/m/XXOnEEfADcNBmzdvNkur12TlNePZBn2o22wH22D/Vh1ztqHeXl5Zh/r0ABkqZycHDz++ONYvnw5/P39yzzm4MGDWLJkCZKSkqAxcw7NtGnTEBMTY/w6OzsbQUFBGDBgAHx8fGzSdllhYSHi4+PRv3//MktzmsREAIBHnToYPHiwTV+7JqmsH8k87EfbYD/aBvux6py9D+UKjjkcGoD8/f3h4uKC9PR0k/vT09MRGBhY6vjTp08jJSUFDz74oPE+g8EAAHB1dUVycjJ2796NjIwMNGnSxHiMXq/HSy+9hMWLFyMlJaXUeXU6HXRlzLlxc3Oz2zdQuee+tQmiRqdzym9eS9nz38iZsB9tg/1oG+zHqnPWPrTkPTs0ALm7uyMsLAzbtm0zLmU3GAzYtm0boqOjSx3ftm1bHDlyxOS+6dOnIycnB0uWLEFQUBAef/xxREZGmhwzcOBAPP7444iKirLbe7EZeRk8N0EkIiKyG4eXwGJiYjB27Fh07doV3bt3x+LFi5Gbm2sMK2PGjEGjRo0QGxsLDw8PtG/f3uT5devWBQDj/X5+fvDz8zM5xs3NDYGBgQgODrb/G6oqrgIjIiKyO4cHoJEjR+Ly5cuYOXMm0tLS0KlTJ2zZssU4MTo1NRVarcNX61cfBiAiIiK7c3gAAoDo6OgyS14AsHPnzgqfu2rVqkrPX9a8H8ViCYyIiMjunGhoRSU4AkRERGR3DEBKwwBERERkdwxASsMSGBERkd0xACkNR4CIiIjsjgFIaRiAiIiI7I4BSGlYAiMiIrI7BiCl4QgQERGR3TEAKQ0DEBERkd0xACmNXAJjACIiIrIbBiClkUeAOAeIiIjIbhiAlIYlMCIiIrtjAFIalsCIiIjsjgFIaVgCIyIisjsGIKVhCYyIiMjuGICUhiUwIiIiu2MAUhqWwIiIiOyOAUhpWAIjIiKyOwYgpWEJjIiIyO4YgJSGJTAiIiK7YwBSGpbAiIiI7I4BSGlYAiMiIrI7BiClYQmMiIjI7hiAlIYlMCIiIrtjAFIaBiAiIiK7YwBSEkkCCgvFbZbAiIiI7IYBSEnkCdAAR4CIiIjsiAFISeTyF8AAREREZEcMQEpScgSIJTAiIiK7YQBSEnkEyNUV0PKfhoiIyF74W1ZJuAKMiIioWjAAKYlcAmP5i4iIyK4YgJSEI0BERETVggFISRiAiIiIqoWroxvgVLKygMuX4ZmRAZw7B7i5mT6emio+swRGRERkVwxA1WnZMrhNm4YBlR3HESAiIiK7YgCqTq6ukDw8YDAYoNVqoSnrGK0WGDmyultGRETkVDgHqDpNmYKi7Gz8+M03KMrOBm7cKP2RmwtMn+7olhIREdVoDEBERETkdBiAiIiIyOkwABEREZHTYQAiIiIip8MARERERE6HAYiIiIicDgMQEREROR0GICIiInI6DEBERETkdBiAiIiIyOkwABEREZHTYQAiIiIip8MARERERE6HAYiIiIicjqujG6BEkiQBALKzs21+7sLCQuTl5SE7Oxtubm42P7+zYD/aBvvRNtiPtsF+rDpn70P597b8e7wiDEBlyMnJAQAEBQU5uCVERERkqZycHNSpU6fCYzSSOTHJyRgMBly8eBHe3t7QaDQ2PXd2djaCgoJw/vx5+Pj42PTczoT9aBvsR9tgP9oG+7HqnL0PJUlCTk4OGjZsCK224lk+HAEqg1arRePGje36Gj4+Pk75zWlr7EfbYD/aBvvRNtiPVefMfVjZyI+Mk6CJiIjI6TAAERERkdNhAKpmOp0Os2bNgk6nc3RTVI39aBvsR9tgP9oG+7Hq2Ifm4yRoIiIicjocASIiIiKnwwBERERETocBiIiIiJwOAxARERE5HQagarR06VI0a9YMHh4eCA8Px/79+x3dJEX73//+hwcffBANGzaERqPBhg0bTB6XJAkzZ85EgwYN4OnpicjISJw8edIxjVWw2NhYdOvWDd7e3qhfvz6GDRuG5ORkk2Nu3ryJSZMmwc/PD7Vr18aIESOQnp7uoBYr07Jly9CxY0fjBnMRERH4+eefjY+zDy03f/58aDQavPDCC8b72I/meeONN6DRaEw+2rZta3yc/Vg5BqBqsm7dOsTExGDWrFlISkpCaGgoBg4ciIyMDEc3TbFyc3MRGhqKpUuXlvn4ggUL8P777yMuLg6JiYmoVasWBg4ciJs3b1ZzS5Vt165dmDRpEvbt24f4+HgUFhZiwIAByM3NNR7z4osv4ocffsC3336LXbt24eLFixg+fLgDW608jRs3xvz583Hw4EH8/vvvuPfeezF06FAcO3YMAPvQUgcOHMDHH3+Mjh07mtzPfjTfnXfeiUuXLhk/EhISjI+xH80gUbXo3r27NGnSJOPXer1eatiwoRQbG+vAVqkHAGn9+vXGrw0GgxQYGCi98847xvuuXbsm6XQ6ac2aNQ5ooXpkZGRIAKRdu3ZJkiT6zc3NTfr222+Nxxw/flwCIO3du9dRzVQFX19f6dNPP2UfWignJ0dq3bq1FB8fL/Xu3VuaPHmyJEn8XrTErFmzpNDQ0DIfYz+ahyNA1aCgoAAHDx5EZGSk8T6tVovIyEjs3bvXgS1Tr7NnzyItLc2kT+vUqYPw8HD2aSWysrIAAHfccQcA4ODBgygsLDTpy7Zt26JJkybsy3Lo9XqsXbsWubm5iIiIYB9aaNKkSbj//vtN+gvg96KlTp48iYYNG6JFixYYNWoUUlNTAbAfzcWLoVaDzMxM6PV6BAQEmNwfEBCAEydOOKhV6paWlgYAZfap/BiVZjAY8MILL6BHjx5o3749ANGX7u7uqFu3rsmx7MvSjhw5goiICNy8eRO1a9fG+vXrERISgsOHD7MPzbR27VokJSXhwIEDpR7j96L5wsPDsWrVKgQHB+PSpUuYPXs2evbsiaNHj7IfzcQAROREJk2ahKNHj5rMFSDzBQcH4/Dhw8jKysJ///tfjB07Frt27XJ0s1Tj/PnzmDx5MuLj4+Hh4eHo5qjaoEGDjLc7duyI8PBwNG3aFN988w08PT0d2DL1YAmsGvj7+8PFxaXUDPz09HQEBgY6qFXqJvcb+9R80dHR+PHHH7Fjxw40btzYeH9gYCAKCgpw7do1k+PZl6W5u7ujVatWCAsLQ2xsLEJDQ7FkyRL2oZkOHjyIjIwMdOnSBa6urnB1dcWuXbvw/vvvw9XVFQEBAexHK9WtWxdt2rTBqVOn+P1oJgagauDu7o6wsDBs27bNeJ/BYMC2bdsQERHhwJapV/PmzREYGGjSp9nZ2UhMTGSf3kaSJERHR2P9+vXYvn07mjdvbvJ4WFgY3NzcTPoyOTkZqamp7MtKGAwG5Ofnsw/N1K9fPxw5cgSHDx82fnTt2hWjRo0y3mY/Wuf69es4ffo0GjRowO9Hczl6FrazWLt2raTT6aRVq1ZJf/31lzR+/Hipbt26UlpamqObplg5OTnSoUOHpEOHDkkApEWLFkmHDh2Szp07J0mSJM2fP1+qW7eutHHjRunPP/+Uhg4dKjVv3ly6ceOGg1uuLBMnTpTq1Kkj7dy5U7p06ZLxIy8vz3jMhAkTpCZNmkjbt2+Xfv/9dykiIkKKiIhwYKuV59VXX5V27dolnT17Vvrzzz+lV199VdJoNNLWrVslSWIfWqvkKjBJYj+a66WXXpJ27twpnT17Vvrtt9+kyMhIyd/fX8rIyJAkif1oDgagavTBBx9ITZo0kdzd3aXu3btL+/btc3STFG3Hjh0SgFIfY8eOlSRJLIWfMWOGFBAQIOl0Oqlfv35ScnKyYxutQGX1IQDps88+Mx5z48YN6dlnn5V8fX0lLy8v6aGHHpIuXbrkuEYr0JNPPik1bdpUcnd3l+rVqyf169fPGH4kiX1ordsDEPvRPCNHjpQaNGggubu7S40aNZJGjhwpnTp1yvg4+7FyGkmSJMeMPRERERE5BucAERERkdNhACIiIiKnwwBERERETocBiIiIiJwOAxARERE5HQYgIiIicjoMQEREROR0GICIqMZISUmBRqPB4cOH7fYaTzzxBIYNG2a38xNR9WAAIiLFeOKJJ6DRaEp93HfffWY9PygoCJcuXUL79u3t3FIiUjtXRzeAiKik++67D5999pnJfTqdzqznuri48GrXRGQWjgARkaLodDoEBgaafPj6+gIANBoNli1bhkGDBsHT0xMtWrTAf//7X+Nzby+BXb16FaNGjUK9evXg6emJ1q1bm4SrI0eO4N5774Wnpyf8/Pwwfvx4XL9+3fi4Xq9HTEwM6tatCz8/P7z88su4/epBBoMBsbGxaN68OTw9PREaGmrSJiJSJgYgIlKVGTNmYMSIEfjjjz8watQoPProozh+/Hi5x/7111/4+eefcfz4cSxbtgz+/v4AgNzcXAwcOBC+vr44cOAAvv32W/z666+Ijo42Pv/dd9/FqlWrsHLlSiQkJODKlStYv369yWvExsbiiy++QFxcHI4dO4YXX3wRo0ePxq5du+zXCURUdQ6+GCsRkdHYsWMlFxcXqVatWiYfb775piRJ4sr2EyZMMHlOeHi4NHHiREmSJOns2bMSAOnQoUOSJEnSgw8+KEVFRZX5Wp988onk6+srXb9+3XjfTz/9JGm1WiktLU2SJElq0KCBtGDBAuPjhYWFUuPGjaWhQ4dKkiRJN2/elLy8vKQ9e/aYnPupp56SHnvsMes7gojsjnOAiEhR+vbti2XLlpncd8cddxhvR0REmDwWERFR7qqviRMnYsSIEUhKSsKAAQMwbNgw3H333QCA48ePIzQ0FLVq1TIe36NHDxgMBiQnJ8PDwwOXLl1CeHi48XFXV1d07drVWAY7deoU8vLy0L9/f5PXLSgoQOfOnS1/80RUbRiAiEhRatWqhVatWtnkXIMGDcK5c+ewefNmxMfHo1+/fpg0aRIWLlxok/PL84V++uknNGrUyOQxcyduE5FjcA4QEanKvn37Sn3drl27co+vV68exo4di9WrV2Px4sX45JNPAADt2rXDH3/8gdzcXOOxv/32G7RaLYKDg1GnTh00aNAAiYmJxseLiopw8OBB49chISHQ6XRITU1Fq1atTD6CgoJs9ZaJyA44AkREipKfn4+0tDST+1xdXY2Tl7/99lt07doV99xzD7766ivs378fK1asKPNcM2fORFhYGO68807k5+fjxx9/NIalUaNGYdasWRg7dizeeOMNXL58Gc899xwef/xxBAQEAAAmT56M+fPno3Xr1mjbti0WLVqEa9euGc/v7e2NKVOm4MUXX4TBYMA999yDrKws/Pbbb/Dx8cHYsWPt0ENEZAsMQESkKFu2bEGDBg1M7gsODsaJEycAALNnz8batWvx7LPPokGDBlizZg1CQkLKPJe7uzumTZuGlJQUeHp6omfPnli7di0AwMvLC7/88gsmT56Mbt26wcvLCyNGjMCiRYuMz3/ppZdw6dIljB07FlqtFk8++SQeeughZGVlGY+ZO3cu6tWrh9jYWJw5cwZ169ZFly5d8Nprr9m6a4jIhjSSdNumFkRECqXRaLB+/XpeioKIqoxzgIiIiMjpMAARERGR0+EcICJSDVbsichWOAJERERETocBiIiIiJwOAxARERE5HQYgIiIicjoMQEREROR0GICIiIjI6TAAERERkdNhACIiIiKnwwBERERETuf/AfUJv1XwYWnpAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    random.seed(i_episode)\n",
    "    confusion_matrix = np.zeros((2,2), dtype=int)\n",
    "    sum_reward = 0\n",
    "    # print(i_episode)\n",
    "\n",
    "    initial_state, info = train_env.reset()\n",
    "    state = torch.tensor(initial_state, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "    rewards = []\n",
    "    log_probs = []\n",
    "\n",
    "    for t in count():\n",
    "        # print(f\"State before step - Max: {state.max()}, Min: {state.min()}, Mean: {state.mean()}\")\n",
    "        # select action\n",
    "        prob_distri, action = select_action(state)\n",
    "\n",
    "        # calculate next state\n",
    "        raw_next_state, reward, terminated, truncated, info = train_env.step(action.item())\n",
    "        row_column_index = info[\"confusion_position\"]\n",
    "        confusion_matrix[row_column_index[0], row_column_index[1]] += 1\n",
    "        # to tensor\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(raw_next_state, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "            if torch.isnan(next_state).any():\n",
    "                raise Exception(next_state)\n",
    "        reward = torch.tensor([reward], device=device, dtype=torch.float32)\n",
    "\n",
    "        # store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        sum_reward += reward.item() if reward.item() == 1 else 0\n",
    "        rewards.append(reward)\n",
    "        log_probs.append(torch.log(prob_distri.gather(1, action)))\n",
    "\n",
    "        # move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # optimize the model\n",
    "        # print(len(rewards), len(log_probs))\n",
    "        if terminated:\n",
    "            episode_rewards.append(sum_reward / (t + 1))\n",
    "            break\n",
    "\n",
    "    # do after the episode\n",
    "    rewards = torch.cat(rewards)\n",
    "    log_probs = torch.cat(log_probs)\n",
    "    episode_memory.push(rewards, log_probs)\n",
    "    if i_episode > 0 and i_episode % BATCH_SIZE == 0:\n",
    "        # print(f\"\\r{i_episode:5}\", end=\"\")\n",
    "        optimize_model()\n",
    "\n",
    "    ## graph\n",
    "    base = confusion_matrix[1, 1] + confusion_matrix[1, 0]\n",
    "    episode_accuracy.append(\n",
    "        confusion_matrix[1, 1] / base if base != 0 else 0.0\n",
    "    )\n",
    "    plot_rewards(episode_accuracy)\n",
    "    ##\n",
    "else:\n",
    "    torch.save(policy_net.state_dict(), \"no3_reinforce.pth\")  # save the model\n",
    "\"\"\"\n",
    "    if i_episode > 0 and i_episode % 100 == 0:\n",
    "        torch.save(policy_net.state_dict(), \"no3_reinforce.pth\")  # save the model\n",
    "\n",
    "        print(f\"Episode {i_episode}: {sum_reward}\")\n",
    "        ac, pr, re, f1, fp = test()\n",
    "        episode_metrics[\"accuracy\"].append(ac)\n",
    "        episode_metrics[\"precision\"].append(pr)\n",
    "        episode_metrics[\"recall\"].append(re)\n",
    "        episode_metrics[\"f1\"].append(f1)\n",
    "        episode_metrics[\"fpr\"].append(fp)\n",
    "        plot_metrics(episode_metrics)\n",
    "\"\"\"\n",
    "\n",
    "# complete the episode\n",
    "plot_metrics(episode_metrics, show_result=True)\n",
    "plot_rewards(episode_rewards, show_result=True)\n",
    "\n",
    "train_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6864d-8fb3-47be-952d-8a2cac4a79c0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Episode {i_episode}: {sum_reward}\")\n",
    "for _ in range(5):\n",
    "    ac, pr, re, f1, fp = test()\n",
    "    episode_metrics[\"accuracy\"].append(ac)\n",
    "    episode_metrics[\"precision\"].append(pr)\n",
    "    episode_metrics[\"recall\"].append(re)\n",
    "    episode_metrics[\"f1\"].append(f1)\n",
    "    episode_metrics[\"fpr\"].append(fp)\n",
    "    print(ac, pr, re, f1, fp)\n",
    "plot_metrics(episode_metrics, show_result=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9740beca7384b44",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bcf181-2fcc-4004-9f2c-5f41762b7f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
